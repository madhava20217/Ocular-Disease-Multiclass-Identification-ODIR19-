{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nBOCxp_qHYHH",
    "outputId": "579f5998-7380-4f04-efde-c6d4d2d004f6"
   },
   "outputs": [],
   "source": [
    "#!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JMOxJ1nqF4SE"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import logging\n",
    "import gdown\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "from torchvision.datasets import VOCSegmentation\n",
    "import torchmetrics\n",
    "import torchvision\n",
    "import albumentations as A\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from scipy.io import loadmat\n",
    "from sklearn.manifold import TSNE\n",
    "from torchmetrics.functional.classification import multiclass_accuracy\n",
    "from torchmetrics.classification import MulticlassF1Score, JaccardIndex, MulticlassPrecision, MulticlassRecall, MulticlassAveragePrecision\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6xU3yEKqHMov",
    "outputId": "830e1b8a-a95c-43df-c1f4-a6dfc47a5108"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "    \n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepro = False\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = '../Datasets/ocular-disease-recognition-odir5k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_FOLDER = ROOT_DIR + \"\"\n",
    "HIST_IMG_FOLDER = ROOT_DIR + \"\"\n",
    "normal_eff_model = \"Saved_Models/\"\n",
    "grey_eff_model = \"Saved_Models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(prepro == True):\n",
    "    IMG_FOLDER = ROOT_DIR + '/inception_preprocessed_images'\n",
    "    HIST_IMG_FOLDER = ROOT_DIR + '/inception_histeq_preprocessed_images'\n",
    "    normal_eff_model += \"eff_b3_normal_preproc.pt\"\n",
    "    grey_eff_model += \"eff_b3_grey_preproc.pt\"\n",
    "else:\n",
    "    IMG_FOLDER = ROOT_DIR + '/preprocessed_images'\n",
    "    HIST_IMG_FOLDER = ROOT_DIR + '/preprocessed_histeq_images'\n",
    "    normal_eff_model +=\"eff_b3_normal.pt\"\n",
    "    grey_eff_model += \"eff_b3_grey.pt\"\n",
    "\n",
    "CSV_PATH = ROOT_DIR + '/dataset_single_eye.csv'\n",
    "TEST_CSV = ROOT_DIR + '/TESTING_dataset_single_eye.csv'\n",
    "TRAIN_RATIO, VAL_RATIO, TEST_RATIO = 0.8, 0.1, 0.1\n",
    "NUM_CLASSES = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODIRDataset(Dataset) :\n",
    "    def __init__(self, X, Y, IMG_FOLDER, HIST_IMG_FOLDER, transform = None) :\n",
    "        '''\n",
    "        id : list of samples ids as string\n",
    "        '''\n",
    "        self.images = X\n",
    "        self.labels = Y\n",
    "        self.image_dir = IMG_FOLDER\n",
    "        self.hist_image_dir = HIST_IMG_FOLDER\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "        t = T.Resize((299,299),interpolation=torchvision.transforms.InterpolationMode.NEAREST)\n",
    "        self.images = [t(torchvision.io.read_image(os.path.join(IMG_FOLDER, x))) for x in X]\n",
    "        self.hist_images = [t(torchvision.io.read_image(os.path.join(HIST_IMG_FOLDER, x))) for x in X]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        #img_path = os.path.join(self.image_dir, self.images[idx])\n",
    "        #hist_img_path = os.path.join(self.hist_image_dir, self.images[idx])\n",
    "        \n",
    "        #image = Image.open(img_path).convert(\"RGB\")\n",
    "        #hist_image = Image.open(hist_img_path)\n",
    "        image = self.images[idx]\n",
    "        hist_image = self.hist_images[idx]\n",
    "\n",
    "        labels = torch.Tensor(self.labels[idx]).long()\n",
    "        # t = T.Resize((299,299),interpolation=torchvision.transforms.InterpolationMode.NEAREST)\n",
    "        # image = t(image)#.long()\n",
    "        # hist_image = t(hist_image)\n",
    "        # image = image.numpy()\n",
    "        # hist_image = hist_image.numpy()\n",
    "        if(self.transform != None) :\n",
    "            image = image.numpy()\n",
    "            hist_image = hist_image.numpy()\n",
    "            image = np.transpose(image, (1,2,0))\n",
    "            image = self.transform(image = image)['image']\n",
    "            image = np.transpose(image, (2,0,1))\n",
    "            \n",
    "            hist_image = np.transpose(hist_image, (1,2,0))\n",
    "            hist_image = self.transform(image = hist_image)['image']\n",
    "            hist_image = np.transpose(hist_image, (2,0,1))\n",
    "            image=torch.tensor(image)\n",
    "            hist_image=torch.tensor(hist_image)\n",
    "\n",
    "        return image, hist_image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path,num_classes=8,device=\"cpu\"):\n",
    "    model = torchvision.models.efficientnet_b3(weights =  torchvision.models.EfficientNet_B3_Weights.DEFAULT).to(device)\n",
    "    num_ftrs = model.classifier[1].in_features\n",
    "    model.classifier[1] = torch.nn.Linear(in_features=num_ftrs, out_features=num_classes, bias=True)\n",
    "    model.classifier[0] = torch.nn.Dropout(p=0.5, inplace=True)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "def load_grey_model(path,num_classes=8,device=\"cpu\"):\n",
    "    model = torchvision.models.efficientnet_b3(weights =  torchvision.models.EfficientNet_B3_Weights.DEFAULT).to(device)\n",
    "    num_ftrs = model.classifier[1].in_features\n",
    "    model.features[0][0] = torch.nn.Conv2d(1, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "    model.classifier[1] = torch.nn.Linear(in_features=num_ftrs, out_features=num_classes, bias=True)\n",
    "    model.classifier[0] = torch.nn.Dropout(p=0.5, inplace=True)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "def predictions(scores) :\n",
    "    \n",
    "    B = scores.shape[0]\n",
    "    predictions = torch.empty(B, NUM_CLASSES)\n",
    "    \n",
    "    for i in range(B) :\n",
    "      pred = torch.empty(NUM_CLASSES,)\n",
    "      for j in range(NUM_CLASSES) : \n",
    "        if(scores[i][j] > 0.5) :\n",
    "          pred[j] = 1\n",
    "        else :\n",
    "          pred[j] = 0\n",
    "      predictions[i] = pred\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class combined_efficientNet():    \n",
    "    def __init__(self, normal_path, grey_path) :\n",
    "        self.normal_efficientNet = load_model(normal_path,num_classes=8,device=\"cuda\")\n",
    "        self.grey_efficientNet = load_grey_model(grey_path,num_classes=8,device=\"cuda\")\n",
    "        \n",
    "    def test_sample(self, sample, sample_hist):\n",
    "        output_normal = torch.sigmoid(self.normal_efficientNet(sample))\n",
    "        output_grey = torch.sigmoid(self.grey_efficientNet(sample_hist))\n",
    "        outputs = torch.add(output_normal, output_grey)\n",
    "        outputs = torch.div(outputs, 2)\n",
    "        return outputs\n",
    "\n",
    "    def test(self, test_loader):\n",
    "        self.normal_efficientNet.eval()\n",
    "        self.grey_efficientNet.eval()\n",
    "        test_loss = 0\n",
    "        test_acc  = 0\n",
    "        AVERAGING = 'micro'\n",
    "        PREC = torchmetrics.classification.MultilabelPrecision(8, average = AVERAGING)#, validate_args = False)\n",
    "        ACC = torchmetrics.classification.MultilabelAccuracy(8, average = AVERAGING)#, validate_args = False)\n",
    "        REC = torchmetrics.classification.MultilabelRecall(8, average = AVERAGING)#, validate_args = False)\n",
    "        F1_SCORE = torchmetrics.classification.MultilabelF1Score(8, average = AVERAGING)#, validate_args = False)\n",
    "        F_BETA_SCORE = torchmetrics.classification.MultilabelFBetaScore(beta = 0.8, num_classes = 8, num_labels = 8, average = AVERAGING)#, validate_args = False)\n",
    "        KAPPA = torchmetrics.classification.MulticlassCohenKappa(8)#, validate_args = False)\n",
    "        AUC = torchmetrics.classification.MultilabelAUROC(8, average = AVERAGING)#, validate_args = False)\n",
    "\n",
    "        for batch_idx, (data, data_hist, targets) in enumerate((test_dataloader_preheld)):\n",
    "            data = data.to(device).float()\n",
    "            data_hist = data_hist.float().to(device)\n",
    "            targets = targets.to(device)\n",
    "            with torch.no_grad():\n",
    "                scores = self.test_sample(data, data_hist)\n",
    "            loss = criterion(scores, targets.float())\n",
    "            test_loss+= loss.item()\n",
    "            predicted = predictions(scores).to(device)\n",
    "            test_acc+= (torch.sum(predicted == targets)/(BATCH_SIZE*8))\n",
    "\n",
    "            predicted = predicted.to('cpu')\n",
    "            targets = targets.to('cpu')\n",
    "            PREC(predicted, targets)\n",
    "            ACC(predicted, targets)\n",
    "            REC(predicted, targets)\n",
    "            F1_SCORE(predicted, targets)\n",
    "            F_BETA_SCORE(predicted, targets)\n",
    "            KAPPA(predicted, targets)\n",
    "            AUC(predicted, targets)\n",
    "\n",
    "\n",
    "        add_prec = PREC.compute()\n",
    "        add_acc = ACC.compute()\n",
    "        add_rec = REC.compute()\n",
    "        add_f1 = F1_SCORE.compute()\n",
    "        add_fbeta = F_BETA_SCORE.compute()\n",
    "        add_kappa = KAPPA.compute()\n",
    "        add_auc = AUC.compute()\n",
    "\n",
    "        avg_test_loss = test_loss/len(test_dataloader_preheld)\n",
    "        avg_test_acc  = test_acc /len(test_dataloader_preheld)\n",
    "\n",
    "        print(\"Acc: {:3f}\\nPrec: {:3f}\\nRecall: {:.3f}\\nF1-score: {:.3f}\\nF-Beta-score: {:.3f}\\nKappa: {:.3f}\\nAUC: {:.3f}\".format(add_acc, add_prec,add_rec, add_f1, add_fbeta, add_kappa, add_auc))\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_class = torch.tensor([1,1.2,1.5,1.5,1.5,1.5, 1.5, 1.2]).to(device)\n",
    "criterion = torch.nn.BCELoss(weight_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Datasets/ocular-disease-recognition-odir5k/dataset_single_eye.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>G</th>\n",
       "      <th>C</th>\n",
       "      <th>A</th>\n",
       "      <th>H</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>970_right.jpg</td>\n",
       "      <td>cataract</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127_left.jpg</td>\n",
       "      <td>proliferative diabetic retinopathy，hypertensiv...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>850_right.jpg</td>\n",
       "      <td>macular epiretinal membrane，moderate non proli...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37_right.jpg</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4421_right.jpg</td>\n",
       "      <td>moderate non proliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5733</th>\n",
       "      <td>199_left.jpg</td>\n",
       "      <td>branch retinal vein occlusion</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>516_right.jpg</td>\n",
       "      <td>moderate non proliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5735</th>\n",
       "      <td>4603_left.jpg</td>\n",
       "      <td>severe nonproliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5736</th>\n",
       "      <td>2132_right.jpg</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5737</th>\n",
       "      <td>4487_right.jpg</td>\n",
       "      <td>mild nonproliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5738 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Image                                           Keywords  N  D  \\\n",
       "0      970_right.jpg                                           cataract  0  0   \n",
       "1       127_left.jpg  proliferative diabetic retinopathy，hypertensiv...  0  1   \n",
       "2      850_right.jpg  macular epiretinal membrane，moderate non proli...  0  1   \n",
       "3       37_right.jpg                                      normal fundus  1  0   \n",
       "4     4421_right.jpg             moderate non proliferative retinopathy  0  1   \n",
       "...              ...                                                ... .. ..   \n",
       "5733    199_left.jpg                      branch retinal vein occlusion  0  0   \n",
       "5734   516_right.jpg             moderate non proliferative retinopathy  0  1   \n",
       "5735   4603_left.jpg                severe nonproliferative retinopathy  0  1   \n",
       "5736  2132_right.jpg                                      normal fundus  1  0   \n",
       "5737  4487_right.jpg                  mild nonproliferative retinopathy  0  1   \n",
       "\n",
       "      G  C  A  H  M  O  \n",
       "0     0  1  0  0  0  0  \n",
       "1     0  0  0  0  0  0  \n",
       "2     0  0  0  0  0  0  \n",
       "3     0  0  0  0  0  0  \n",
       "4     0  0  0  0  0  0  \n",
       "...  .. .. .. .. .. ..  \n",
       "5733  0  0  0  0  0  1  \n",
       "5734  0  0  0  0  0  0  \n",
       "5735  0  0  0  0  0  0  \n",
       "5736  0  0  0  0  0  0  \n",
       "5737  0  0  0  0  0  0  \n",
       "\n",
       "[5738 rows x 10 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv = pd.read_csv(CSV_PATH)\n",
    "print(CSV_PATH)\n",
    "\n",
    "csv = csv[csv['NOT DECISIVE'] == 0]\n",
    "\n",
    "csv['img_exists'] = csv['Image'].apply(lambda x: os.path.isfile(IMG_FOLDER + \"/\" + x))\n",
    "\n",
    "# drop the rows for which the file does not exist\n",
    "csv = csv[csv['img_exists']]\n",
    "\n",
    "csv.drop(columns = ['ID', 'eye', 'Patient Age',\t'Patient Sex', 'NOT DECISIVE', 'img_exists'], inplace = True)\n",
    "csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5738,)\n",
      "(5738, 8)\n"
     ]
    }
   ],
   "source": [
    "X = csv['Image'].to_numpy()\n",
    "Y = csv.drop(['Image', 'Keywords'], axis = 1).to_numpy()\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ODIRDataset(X, Y, IMG_FOLDER, HIST_IMG_FOLDER, transform = None)\n",
    "test_dataloader_preheld = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "EfficientNet = combined_efficientNet(normal_eff_model, grey_eff_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.929461\n",
      "Prec: 0.802517\n",
      "Recall: 0.578\n",
      "F1-score: 0.672\n",
      "F-Beta-score: 0.697\n",
      "Kappa: 0.634\n",
      "AUC: 0.779\n"
     ]
    }
   ],
   "source": [
    "EfficientNet.test(test_dataloader_preheld)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics (With Flipping):\n",
    "|Metric(micro)|Value|-|Metric(weighted)|Value|\n",
    "|:-----------:|-----|-|----------------|-----|\n",
    "|Acc          |0.874|-|Acc             |0.707|\n",
    "|Prec:        |0.370|-|Prec:           |0.303|\n",
    "|Recall       |0.005|-|Recall          |0.005|\n",
    "|F1-score     |0.010|-|F1-score        |0.010|\n",
    "|F-Beta-score |0.013|-|F-Beta-score    |0.013|\n",
    "|Kappa        |0.007|-|Kappa           |0.007|\n",
    "|AUC          |0.502|-|AUC             |0.501|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics (No Flipping)\n",
    "\n",
    "|Metric(micro)|Value|-|Metric(weighted)|Value|\n",
    "|:-----------:|-----|-|----------------|-----|\n",
    "|Acc          |0.929|-|Acc             |0.852|\n",
    "|Prec:        |0.802|-|Prec:           |0.718|\n",
    "|Recall       |0.578|-|Recall          |0.578|\n",
    "|F1-score     |0.672|-|F1-score        |0.624|\n",
    "|F-Beta-score |0.697|-|F-Beta-score    |0.638|\n",
    "|Kappa        |0.634|-|Kappa           |0.634|\n",
    "|AUC          |0.779|-|AUC             |0.746|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing = False\n",
    "\n",
    "Acc: 0.929461\n",
    "Prec: 0.802517\n",
    "Recall: 0.578\n",
    "F1-score: 0.672\n",
    "F-Beta-score: 0.697\n",
    "Kappa: 0.634\n",
    "AUC: 0.779"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessed = True\n",
    "\n",
    "Acc: 0.874543\n",
    "Prec: 0.370370\n",
    "Recall: 0.005\n",
    "F1-score: 0.010\n",
    "F-Beta-score: 0.013\n",
    "Kappa: 0.007\n",
    "AUC: 0.502"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.11.3 ('torchnew')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "aae2c75324e7fdf5ebd22146e2daffaa477f8ea149f0e685be4c317c2939a685"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
