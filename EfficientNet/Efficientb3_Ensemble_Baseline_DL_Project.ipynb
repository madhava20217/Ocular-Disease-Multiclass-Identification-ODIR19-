{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nBOCxp_qHYHH",
    "outputId": "579f5998-7380-4f04-efde-c6d4d2d004f6"
   },
   "outputs": [],
   "source": [
    "#!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "JMOxJ1nqF4SE"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import logging\n",
    "import gdown\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torchvision.datasets import VOCSegmentation\n",
    "import torchmetrics\n",
    "import torchvision\n",
    "import albumentations as A\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from scipy.io import loadmat\n",
    "from sklearn.manifold import TSNE\n",
    "from torchmetrics.functional.classification import multiclass_accuracy\n",
    "from torchmetrics.classification import MulticlassF1Score, JaccardIndex, MulticlassPrecision, MulticlassRecall, MulticlassAveragePrecision\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6xU3yEKqHMov",
    "outputId": "830e1b8a-a95c-43df-c1f4-a6dfc47a5108"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "    \n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepro = False\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = '../Datasets/ocular-disease-recognition-odir5k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_FOLDER = ROOT_DIR + \"\"\n",
    "HIST_IMG_FOLDER = ROOT_DIR + \"\"\n",
    "normal_eff_model = \"Saved_Models/\"\n",
    "grey_eff_model = \"Saved_Models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(prepro == True):\n",
    "    IMG_FOLDER = ROOT_DIR + '/inception_preprocessed_images'\n",
    "    HIST_IMG_FOLDER = ROOT_DIR + '/inception_histeq_preprocessed_images'\n",
    "    normal_eff_model += \"eff_b3_normal_preproc.pt\"\n",
    "    grey_eff_model += \"eff_b3_grey_preproc.pt\"\n",
    "else:\n",
    "    IMG_FOLDER = ROOT_DIR + '/preprocessed_images'\n",
    "    HIST_IMG_FOLDER = ROOT_DIR + '/preprocessed_histeq_images'\n",
    "    normal_eff_model +=\"eff_b3_normal.pt\"\n",
    "    grey_eff_model += \"eff_b3_grey.pt\"\n",
    "\n",
    "CSV_PATH = ROOT_DIR + '/dataset_single_eye.csv'\n",
    "TEST_CSV = ROOT_DIR + '/TESTING_dataset_single_eye.csv'\n",
    "TRAIN_RATIO, VAL_RATIO, TEST_RATIO = 0.8, 0.1, 0.1\n",
    "NUM_CLASSES = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODIRDataset(Dataset) :\n",
    "    def __init__(self, X, Y, IMG_FOLDER, HIST_IMG_FOLDER, transform = None) :\n",
    "        '''\n",
    "        id : list of samples ids as string\n",
    "        '''\n",
    "        self.images = X\n",
    "        self.labels = Y\n",
    "        self.image_dir = IMG_FOLDER\n",
    "        self.hist_image_dir = HIST_IMG_FOLDER\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_path = os.path.join(self.image_dir, self.images[idx])\n",
    "        hist_img_path = os.path.join(self.hist_image_dir, self.images[idx])\n",
    "        \n",
    "        #image = Image.open(img_path).convert(\"RGB\")\n",
    "        #hist_image = Image.open(hist_img_path)\n",
    "        image = torchvision.io.read_image(img_path)\n",
    "        hist_image = torchvision.io.read_image(hist_img_path)\n",
    "\n",
    "        labels = torch.Tensor(self.labels[idx]).long()\n",
    "        t = T.Resize((299,299),interpolation=torchvision.transforms.InterpolationMode.NEAREST)\n",
    "        image = t(image)#.long()\n",
    "        hist_image = t(hist_image)\n",
    "        image = image.numpy()\n",
    "        hist_image = hist_image.numpy()\n",
    "        if(self.transform != None) :\n",
    "            image = np.transpose(image, (1,2,0))\n",
    "            image = self.transform(image = image)['image']\n",
    "            image = np.transpose(image, (2,0,1))\n",
    "            \n",
    "            hist_image = np.transpose(hist_image, (1,2,0))\n",
    "            hist_image = self.transform(image = hist_image)['image']\n",
    "            hist_image = np.transpose(hist_image, (2,0,1))\n",
    "        image=torch.tensor(image)\n",
    "        hist_image=torch.tensor(hist_image)\n",
    "\n",
    "        return image, hist_image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path,num_classes=8,device=\"cpu\"):\n",
    "    model = torchvision.models.efficientnet_b3(parameters = {'weights': torchvision.models.EfficientNet_B3_Weights.DEFAULT}).to(device)\n",
    "    num_ftrs = model.classifier[1].in_features\n",
    "    model.classifier[1] = torch.nn.Linear(in_features=num_ftrs, out_features=num_classes, bias=True)\n",
    "    model.classifier[0] = torch.nn.Dropout(p=0.5, inplace=True)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "def load_grey_model(path,num_classes=8,device=\"cpu\"):\n",
    "    model = torchvision.models.efficientnet_b3(parameters = {'weights': torchvision.models.EfficientNet_B3_Weights.DEFAULT}).to(device)\n",
    "    num_ftrs = model.classifier[1].in_features\n",
    "    model.features[0][0] = torch.nn.Conv2d(1, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "    model.classifier[1] = torch.nn.Linear(in_features=num_ftrs, out_features=num_classes, bias=True)\n",
    "    model.classifier[0] = torch.nn.Dropout(p=0.5, inplace=True)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "def predictions(scores) :\n",
    "    \n",
    "    B = scores.shape[0]\n",
    "    predictions = torch.empty(B, NUM_CLASSES)\n",
    "    \n",
    "    for i in range(B) :\n",
    "      pred = torch.empty(NUM_CLASSES,)\n",
    "      for j in range(NUM_CLASSES) : \n",
    "        if(scores[i][j] > 0.5) :\n",
    "          pred[j] = 1\n",
    "        else :\n",
    "          pred[j] = 0\n",
    "      predictions[i] = pred\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class combined_efficientNet():    \n",
    "    def __init__(self, normal_path, grey_path) :\n",
    "        self.normal_efficientNet = load_model(normal_path,num_classes=8,device=\"cuda\")\n",
    "        self.grey_efficientNet = load_grey_model(grey_path,num_classes=8,device=\"cuda\")\n",
    "        \n",
    "    def test_sample(self, sample, sample_hist):\n",
    "        output_normal = torch.sigmoid(self.normal_efficientNet(sample))\n",
    "        output_grey = torch.sigmoid(self.grey_efficientNet(sample_hist))\n",
    "        outputs = torch.add(output_normal, output_grey)\n",
    "        outputs = torch.div(outputs, 2)\n",
    "        return outputs\n",
    "\n",
    "    def test(self, test_loader):\n",
    "        self.normal_efficientNet.eval()\n",
    "        self.grey_efficientNet.eval()\n",
    "        test_loss = 0\n",
    "        test_acc  = 0\n",
    "        AVERAGING = 'weighted'\n",
    "        PREC = torchmetrics.classification.MultilabelPrecision(8, average = AVERAGING)#, validate_args = False)\n",
    "        ACC = torchmetrics.classification.MultilabelAccuracy(8, average = AVERAGING)#, validate_args = False)\n",
    "        REC = torchmetrics.classification.MultilabelRecall(8, average = AVERAGING)#, validate_args = False)\n",
    "        F1_SCORE = torchmetrics.classification.MultilabelF1Score(8, average = AVERAGING)#, validate_args = False)\n",
    "        F_BETA_SCORE = torchmetrics.classification.MultilabelFBetaScore(beta = 0.8, num_classes = 8, num_labels = 8, average = AVERAGING)#, validate_args = False)\n",
    "        KAPPA = torchmetrics.classification.MulticlassCohenKappa(8)#, validate_args = False)\n",
    "        AUC = torchmetrics.classification.MultilabelAUROC(8, average = AVERAGING)#, validate_args = False)\n",
    "\n",
    "        for batch_idx, (data, data_hist, targets) in enumerate((test_dataloader_preheld)):\n",
    "            data = data.to(device).float()\n",
    "            data_hist = data_hist.float().to(device)\n",
    "            targets = targets.to(device)\n",
    "            with torch.no_grad():\n",
    "                scores = self.test_sample(data, data_hist)\n",
    "            loss = criterion(scores, targets.float())\n",
    "            test_loss+= loss.item()\n",
    "            predicted = predictions(scores).to(device)\n",
    "            test_acc+= (torch.sum(predicted == targets)/(BATCH_SIZE*8))\n",
    "\n",
    "            predicted = predicted.to('cpu')\n",
    "            targets = targets.to('cpu')\n",
    "            PREC(predicted, targets)\n",
    "            ACC(predicted, targets)\n",
    "            REC(predicted, targets)\n",
    "            F1_SCORE(predicted, targets)\n",
    "            F_BETA_SCORE(predicted, targets)\n",
    "            KAPPA(predicted, targets)\n",
    "            AUC(predicted, targets)\n",
    "\n",
    "\n",
    "        add_prec = PREC.compute()\n",
    "        add_acc = ACC.compute()\n",
    "        add_rec = REC.compute()\n",
    "        add_f1 = F1_SCORE.compute()\n",
    "        add_fbeta = F_BETA_SCORE.compute()\n",
    "        add_kappa = KAPPA.compute()\n",
    "        add_auc = AUC.compute()\n",
    "\n",
    "        avg_test_loss = test_loss/len(test_dataloader_preheld)\n",
    "        avg_test_acc  = test_acc /len(test_dataloader_preheld)\n",
    "\n",
    "        print(\"Acc: {:3f}\\nPrec: {:3f}\\nRecall: {:.3f}\\nF1-score: {:.3f}\\nF-Beta-score: {:.3f}\\nKappa: {:.3f}\\nAUC: {:.3f}\".format(add_acc, add_prec,add_rec, add_f1, add_fbeta, add_kappa, add_auc))\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_class = torch.tensor([1,1.2,1.5,1.5,1.5,1.5, 1.5, 1.2]).to(device)\n",
    "criterion = torch.nn.BCELoss(weight_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Datasets/ocular-disease-recognition-odir5k/dataset_single_eye.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>G</th>\n",
       "      <th>C</th>\n",
       "      <th>A</th>\n",
       "      <th>H</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>970_right.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127_left.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>850_right.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37_right.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4421_right.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5733</th>\n",
       "      <td>199_left.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>516_right.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5735</th>\n",
       "      <td>4603_left.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5736</th>\n",
       "      <td>2132_right.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5737</th>\n",
       "      <td>4487_right.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5738 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Image  N  D  G  C  A  H  M  O\n",
       "0      970_right.jpg  0  0  0  1  0  0  0  0\n",
       "1       127_left.jpg  0  1  0  0  0  0  0  0\n",
       "2      850_right.jpg  0  1  0  0  0  0  0  0\n",
       "3       37_right.jpg  1  0  0  0  0  0  0  0\n",
       "4     4421_right.jpg  0  1  0  0  0  0  0  0\n",
       "...              ... .. .. .. .. .. .. .. ..\n",
       "5733    199_left.jpg  0  0  0  0  0  0  0  1\n",
       "5734   516_right.jpg  0  1  0  0  0  0  0  0\n",
       "5735   4603_left.jpg  0  1  0  0  0  0  0  0\n",
       "5736  2132_right.jpg  1  0  0  0  0  0  0  0\n",
       "5737  4487_right.jpg  0  1  0  0  0  0  0  0\n",
       "\n",
       "[5738 rows x 9 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv = pd.read_csv(CSV_PATH)\n",
    "print(CSV_PATH)\n",
    "\n",
    "csv = csv[csv['NOT DECISIVE'] == 0]\n",
    "\n",
    "csv['img_exists'] = csv['Image'].apply(lambda x: os.path.isfile(IMG_FOLDER + \"/\" + x))\n",
    "\n",
    "# drop the rows for which the file does not exist\n",
    "csv = csv[csv['img_exists']]\n",
    "\n",
    "csv.drop(columns = ['ID', 'eye', 'Patient Age',\t'Patient Sex', 'NOT DECISIVE', 'img_exists'], inplace = True)\n",
    "csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5738,)\n",
      "(5738, 8)\n"
     ]
    }
   ],
   "source": [
    "X = csv['Image'].to_numpy()\n",
    "Y = csv.drop(['Image'], axis = 1).to_numpy()\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ODIRDataset(X, Y, IMG_FOLDER, HIST_IMG_FOLDER, transform = None)\n",
    "test_dataloader_preheld = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "EfficientNet = combined_efficientNet(normal_eff_model, grey_eff_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.707292\n",
      "Prec: 0.303482\n",
      "Recall: 0.005\n",
      "F1-score: 0.010\n",
      "F-Beta-score: 0.013\n",
      "Kappa: 0.007\n",
      "AUC: 0.501\n"
     ]
    }
   ],
   "source": [
    "EfficientNet.test(test_dataloader_preheld)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics (With Flipping):\n",
    "|Metric(micro)|Value|-|Metric(weighted)|Value|\n",
    "|:-----------:|-----|-|----------------|-----|\n",
    "|Acc          |0.874|-|Acc             |0.707|\n",
    "|Prec:        |0.370|-|Prec:           |0.303|\n",
    "|Recall       |0.005|-|Recall          |0.005|\n",
    "|F1-score     |0.010|-|F1-score        |0.010|\n",
    "|F-Beta-score |0.013|-|F-Beta-score    |0.013|\n",
    "|Kappa        |0.007|-|Kappa           |0.007|\n",
    "|AUC          |0.502|-|AUC             |0.501|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics (No Flipping)\n",
    "\n",
    "|Metric(micro)|Value|-|Metric(weighted)|Value|\n",
    "|:-----------:|-----|-|----------------|-----|\n",
    "|Acc          |0.929|-|Acc             |0.852|\n",
    "|Prec:        |0.802|-|Prec:           |0.718|\n",
    "|Recall       |0.578|-|Recall          |0.578|\n",
    "|F1-score     |0.672|-|F1-score        |0.624|\n",
    "|F-Beta-score |0.697|-|F-Beta-score    |0.638|\n",
    "|Kappa        |0.634|-|Kappa           |0.634|\n",
    "|AUC          |0.779|-|AUC             |0.746|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing = False\n",
    "\n",
    "Acc: 0.929461\n",
    "Prec: 0.802517\n",
    "Recall: 0.578\n",
    "F1-score: 0.672\n",
    "F-Beta-score: 0.697\n",
    "Kappa: 0.634\n",
    "AUC: 0.779"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessed = True\n",
    "\n",
    "Acc: 0.874543\n",
    "Prec: 0.370370\n",
    "Recall: 0.005\n",
    "F1-score: 0.010\n",
    "F-Beta-score: 0.013\n",
    "Kappa: 0.007\n",
    "AUC: 0.502"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "c58e9361bde7ca617934da376e83056db506761bdc9593ca2087fabac973f609"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
