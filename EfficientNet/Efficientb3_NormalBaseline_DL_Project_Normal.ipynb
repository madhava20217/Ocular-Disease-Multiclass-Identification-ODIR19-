{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nBOCxp_qHYHH",
    "outputId": "579f5998-7380-4f04-efde-c6d4d2d004f6"
   },
   "outputs": [],
   "source": [
    "#!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JMOxJ1nqF4SE"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import logging\n",
    "import gdown\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "#from torchsummary import summary\n",
    "from torchvision.datasets import VOCSegmentation\n",
    "import torchmetrics\n",
    "import torchvision\n",
    "import albumentations as A\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from scipy.io import loadmat\n",
    "from sklearn.manifold import TSNE\n",
    "from torchmetrics.functional.classification import multiclass_accuracy\n",
    "from torchmetrics.classification import MulticlassF1Score, JaccardIndex, MulticlassPrecision, MulticlassRecall, MulticlassAveragePrecision\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6xU3yEKqHMov",
    "outputId": "830e1b8a-a95c-43df-c1f4-a6dfc47a5108"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "    \n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "BRIQN1ehjjy_"
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = '/content/drive/MyDrive/Project/Datasets/ocular-disease-recognition-odir5k'\n",
    "ROOT_DIR = '../Datasets/ocular-disease-recognition-odir5k/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "264dKYHtkr_t"
   },
   "outputs": [],
   "source": [
    "IMAGE_FOLDER = ROOT_DIR + '/preprocessed_images'\n",
    "CSV_PATH = ROOT_DIR + '/dataset_single_eye.csv'\n",
    "TEST_CSV = ROOT_DIR + '/TESTING_dataset_single_eye.csv'\n",
    "\n",
    "TRAIN_RATIO, VAL_RATIO, TEST_RATIO = 0.8, 0.1, 0.1\n",
    "\n",
    "NUM_CLASSES = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: Efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageResizer:\n",
    "    \n",
    "    def __init__(self, image_width, quality, source_folder, destination_folder, file_name, keep_aspect_ratio):\n",
    "        self.image_width = image_width\n",
    "        self.quality = quality\n",
    "        self.source_folder = source_folder\n",
    "        self.destination_folder= destination_folder\n",
    "        self.file_name = file_name\n",
    "        self.keep_aspect_ration = keep_aspect_ratio\n",
    "\n",
    "    def run(self):\n",
    "\n",
    "        # We load the original file, we resize it to a smaller width and correspondent height and\n",
    "        # also mirror the image when we find a right eye image so they are all left eyes\n",
    "\n",
    "        file = os.path.join(self.source_folder, self.file_name)\n",
    "        img = Image.open(file)\n",
    "\n",
    "        if self.keep_aspect_ration:\n",
    "            width_percentage = (self.image_width / float(img.size[0]))\n",
    "            height_size = int((float(img.size[1]) * float(width_percentage)))\n",
    "            img = img.resize((self.image_width, height_size), Image.ANTIALIAS)\n",
    "        else:\n",
    "            img = img.resize((self.image_width, self.image_width), Image.ANTIALIAS)\n",
    "        if \"right\" in self.file_name:\n",
    "            img.transpose(Image.Transpose.FLIP_LEFT_RIGHT).save(os.path.join(self.destination_folder, self.file_name), optimize=True, quality=self.quality)\n",
    "        else:\n",
    "            img.save(os.path.join(self.destination_folder, self.file_name), optimize=True, quality=self.quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_PATH = ROOT_DIR + '/preprocessed_images'\n",
    "DEST_PATH = ROOT_DIR + '/inception_preprocessed_images'\n",
    "\n",
    "os.makedirs(DEST_PATH, exist_ok = True)\n",
    "\n",
    "# files = [f for f in os.listdir(SRC_PATH) if os.path.isfile(os.path.join(SRC_PATH, f))]\n",
    "# for file in tqdm(files):\n",
    "#     ImageResizer(image_width = 299, quality = 100, source_folder = SRC_PATH, destination_folder = DEST_PATH, file_name = file, keep_aspect_ratio = False).run()\n",
    "\n",
    "# files = [f for f in os.listdir(SRC_PATH) if not(os.path.isfile(os.path.join(DEST_PATH, f)))]\n",
    "# print(len(files))\n",
    "\n",
    "# for file in tqdm(files):\n",
    "#     ImageResizer(image_width = 299, quality = 100, source_folder = SRC_PATH, destination_folder = DEST_PATH, file_name = file, keep_aspect_ratio = False).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NA2ad5WWnd1n"
   },
   "outputs": [],
   "source": [
    "# Mount Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "id": "a-tNFXrTHAc9",
    "outputId": "cf1acb83-8516-473c-f260-5c621e9dde6b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>G</th>\n",
       "      <th>C</th>\n",
       "      <th>A</th>\n",
       "      <th>H</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>970_right.jpg</td>\n",
       "      <td>cataract</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127_left.jpg</td>\n",
       "      <td>proliferative diabetic retinopathy，hypertensiv...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>850_right.jpg</td>\n",
       "      <td>macular epiretinal membrane，moderate non proli...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37_right.jpg</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4421_right.jpg</td>\n",
       "      <td>moderate non proliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5733</th>\n",
       "      <td>199_left.jpg</td>\n",
       "      <td>branch retinal vein occlusion</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>516_right.jpg</td>\n",
       "      <td>moderate non proliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5735</th>\n",
       "      <td>4603_left.jpg</td>\n",
       "      <td>severe nonproliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5736</th>\n",
       "      <td>2132_right.jpg</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5737</th>\n",
       "      <td>4487_right.jpg</td>\n",
       "      <td>mild nonproliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5738 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Image                                           Keywords  N  D  \\\n",
       "0      970_right.jpg                                           cataract  0  0   \n",
       "1       127_left.jpg  proliferative diabetic retinopathy，hypertensiv...  0  1   \n",
       "2      850_right.jpg  macular epiretinal membrane，moderate non proli...  0  1   \n",
       "3       37_right.jpg                                      normal fundus  1  0   \n",
       "4     4421_right.jpg             moderate non proliferative retinopathy  0  1   \n",
       "...              ...                                                ... .. ..   \n",
       "5733    199_left.jpg                      branch retinal vein occlusion  0  0   \n",
       "5734   516_right.jpg             moderate non proliferative retinopathy  0  1   \n",
       "5735   4603_left.jpg                severe nonproliferative retinopathy  0  1   \n",
       "5736  2132_right.jpg                                      normal fundus  1  0   \n",
       "5737  4487_right.jpg                  mild nonproliferative retinopathy  0  1   \n",
       "\n",
       "      G  C  A  H  M  O  \n",
       "0     0  1  0  0  0  0  \n",
       "1     0  0  0  0  0  0  \n",
       "2     0  0  0  0  0  0  \n",
       "3     0  0  0  0  0  0  \n",
       "4     0  0  0  0  0  0  \n",
       "...  .. .. .. .. .. ..  \n",
       "5733  0  0  0  0  0  1  \n",
       "5734  0  0  0  0  0  0  \n",
       "5735  0  0  0  0  0  0  \n",
       "5736  0  0  0  0  0  0  \n",
       "5737  0  0  0  0  0  0  \n",
       "\n",
       "[5738 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv = pd.read_csv(CSV_PATH)\n",
    "\n",
    "csv = csv[csv['NOT DECISIVE'] == 0]\n",
    "\n",
    "csv['img_exists'] = csv['Image'].apply(lambda x: os.path.isfile(IMAGE_FOLDER + \"/\" + x))\n",
    "\n",
    "# drop the rows for which the file does not exist\n",
    "csv = csv[csv['img_exists']]\n",
    "\n",
    "csv.drop(columns = ['ID', 'eye', 'Patient Age',\t'Patient Sex', 'NOT DECISIVE', 'img_exists'], inplace = True)\n",
    "csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-bdShfGZqaGv"
   },
   "outputs": [],
   "source": [
    "# images = [img.split('.', 1)[0] for img in os.listdir(IMAGE_FOLDER) if os.path.isfile(os.path.join(IMAGE_FOLDER, img))]\n",
    "# print(images[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uIFJ65l8Jwno",
    "outputId": "e3405171-c0b8-4fee-b9b4-3ea69fba7484"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5738,)\n",
      "(5738, 8)\n"
     ]
    }
   ],
   "source": [
    "X = csv['Image'].to_numpy()\n",
    "Y = csv.drop(['Image', \"Keywords\"], axis = 1).to_numpy()\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "EoA_pu9vpJJb"
   },
   "outputs": [],
   "source": [
    "class ODIRDataset(Dataset) :\n",
    "    def __init__(self, X, Y, IMG_FOLDER, HIST_IMG_FOLDER, transform = None) :\n",
    "        '''\n",
    "        id : list of samples ids as string\n",
    "        '''\n",
    "        self.images = X\n",
    "        self.labels = Y\n",
    "        self.image_dir = IMG_FOLDER\n",
    "        self.hist_image_dir = HIST_IMG_FOLDER\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "        t = T.Resize((299,299),interpolation=torchvision.transforms.InterpolationMode.NEAREST)\n",
    "        self.images = [t(torchvision.io.read_image(os.path.join(IMG_FOLDER, x))) for x in X]\n",
    "        self.hist_images = [t(torchvision.io.read_image(os.path.join(HIST_IMG_FOLDER, x))) for x in X]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        #img_path = os.path.join(self.image_dir, self.images[idx])\n",
    "        #hist_img_path = os.path.join(self.hist_image_dir, self.images[idx])\n",
    "        \n",
    "        #image = Image.open(img_path).convert(\"RGB\")\n",
    "        #hist_image = Image.open(hist_img_path)\n",
    "        image = self.images[idx]\n",
    "        hist_image = self.hist_images[idx]\n",
    "\n",
    "        labels = torch.Tensor(self.labels[idx]).long()\n",
    "        # t = T.Resize((299,299),interpolation=torchvision.transforms.InterpolationMode.NEAREST)\n",
    "        # image = t(image)#.long()\n",
    "        # hist_image = t(hist_image)\n",
    "        # image = image.numpy()\n",
    "        # hist_image = hist_image.numpy()\n",
    "        if(self.transform != None) :\n",
    "            image = image.numpy()\n",
    "            hist_image = hist_image.numpy()\n",
    "            image = np.transpose(image, (1,2,0))\n",
    "            image = self.transform(image = image)['image']\n",
    "            image = np.transpose(image, (2,0,1))\n",
    "            \n",
    "            hist_image = np.transpose(hist_image, (1,2,0))\n",
    "            hist_image = self.transform(image = hist_image)['image']\n",
    "            hist_image = np.transpose(hist_image, (2,0,1))\n",
    "            image=torch.tensor(image)\n",
    "            hist_image=torch.tensor(hist_image)\n",
    "\n",
    "        return image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Wu2AfXqUtb8P"
   },
   "outputs": [],
   "source": [
    "def train_val_test_split(dataset, train_percent=0.75, val_percent=0.15, test_percent=0.1, seed=None):\n",
    "    \n",
    "    # Given a pytorch Dataset, split it\n",
    "\n",
    "    assert len(X) == len(Y), \"X and Y should have the same length\"\n",
    "    assert round(train_percent + val_percent + test_percent,1) == 1.0, \"Train, validation, and test percentages should add up to 1.0\"\n",
    "\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    train_size = int(train_percent * len(dataset))\n",
    "    val_size = int(val_percent * len(dataset))\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "    # use random_split to split the dataset into train, val, and test sets\n",
    "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Lh25UWJhtgH6"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "RANDOM_SEED = 69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "qgQPtC7NsPsl"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ODIRDataset.__init__() missing 1 required positional argument: 'HIST_IMG_FOLDER'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ODIR_Dataset \u001b[38;5;241m=\u001b[39m ODIRDataset(X, Y, IMAGE_FOLDER, transform \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m train_dataset, val_dataset, test_dataset \u001b[38;5;241m=\u001b[39m train_val_test_split(ODIR_Dataset, TRAIN_RATIO, VAL_RATIO, TEST_RATIO, RANDOM_SEED)\n\u001b[0;32m      5\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: ODIRDataset.__init__() missing 1 required positional argument: 'HIST_IMG_FOLDER'"
     ]
    }
   ],
   "source": [
    "ODIR_Dataset = ODIRDataset(X, Y, IMAGE_FOLDER, transform = None)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = train_val_test_split(ODIR_Dataset, TRAIN_RATIO, VAL_RATIO, TEST_RATIO, RANDOM_SEED)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n1MxByrstyYT",
    "outputId": "c8f1e96e-9147-4251-cf37-4ed838592579"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jsT3OwbrnbSV",
    "outputId": "79084279-1119-45d2-900f-2ba84b3fac07"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader))\n",
    "print(len(val_dataloader))\n",
    "print(len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "evgTKEbXt9aS",
    "outputId": "1740856a-c886-459c-d69e-eaab0d3b45fb"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "train_sample, train_label = train_dataset[9]\n",
    "\n",
    "print(train_sample.shape)\n",
    "\n",
    "image_array = np.transpose(train_sample, (1, 2, 0))\n",
    "plt.imshow(image_array)\n",
    "plt.show()\n",
    "\n",
    "# print(train_sample)\n",
    "print(train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfl6bBsqoZPB"
   },
   "source": [
    "### **MODEL ARCHITECTURE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BXZCtaFUofNy"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 8\n",
    "LEARNING_RATE = 0.01\n",
    "DECAY = 1e-6 \n",
    "MOMENTUM = 0.9\n",
    "NUM_EPOCHS = 100\n",
    "PATIENCE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ETKx9rseoGDO",
    "outputId": "8759e154-dc81-41ab-b890-ba401a5798c9"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\n",
    "# model = models.inception_v3(weights=torchvision.models.Inception_V3_Weights.DEFAULT)\n",
    "model = torchvision.models.efficientnet_b3(parameters = {'weights': torchvision.models.EfficientNet_B3_Weights.DEFAULT}).to(device)\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "NUM_CLASSES = 8\n",
    "model.classifier[1] = torch.nn.Linear(in_features=num_ftrs, out_features=NUM_CLASSES, bias=True)\n",
    "model.classifier[0] = torch.nn.Dropout(p=0.5, inplace=True)\n",
    "model = model.to(device)\n",
    "\n",
    "# Freeze the weights of the base model\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# Replace the top layers of the base model\n",
    "# num_features = model.fc.in_features\n",
    "\n",
    "# model.fc = nn.Sequential(\n",
    "#     nn.Linear(num_features, 1024),\n",
    "#     nn.ReLU(inplace=True),\n",
    "#     nn.Linear(1024, NUM_CLASSES),\n",
    "#     nn.Sigmoid()\n",
    "# )\n",
    "\n",
    "# model = model.to(device)\n",
    "\n",
    "# Print the model summary\n",
    "# summary(model, (3, 299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ff0YXiFiH2LR"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def binary_cross_entropy(y_true, y_pred):\n",
    "    epsilon = 1e-15\n",
    "    y_pred = torch.clamp(y_pred, min = epsilon, max = 1-epsilon)\n",
    "    loss = -(y_true * torch.log(y_pred) + (1 - y_true) * torch.log(1 - y_pred))\n",
    "    mean_loss = torch.mean(loss)\n",
    "    return mean_loss\n",
    "\n",
    "def criterion(y_true_batch, y_pred_batch) :\n",
    "    weight_class = torch.tensor([1,1.2,1.5,1.5,1.5,1.5, 1.5, 1.2]).to(device)\n",
    "    criterion = torch.nn.BCELoss(weight_class)\n",
    "    B = y_true_batch.shape[0]\n",
    "    loss = 0 \n",
    "    for i in range(B) :\n",
    "      loss += criterion(y_pred_batch[i],y_true_batch[i])\n",
    "    return loss/B \n",
    "\n",
    "def predictions(scores) :\n",
    "    \n",
    "    B = scores.shape[0]\n",
    "    predictions = torch.empty(B, NUM_CLASSES)\n",
    "    \n",
    "    for i in range(B) :\n",
    "      pred = torch.empty(NUM_CLASSES,)\n",
    "      for j in range(NUM_CLASSES) : \n",
    "        if(scores[i][j] > 0.5) :\n",
    "          pred[j] = 1\n",
    "        else :\n",
    "          pred[j] = 0\n",
    "      predictions[i] = pred\n",
    "\n",
    "    return predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hmCIgQCclmTs"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "class EarlyStopping:\n",
    "\n",
    "    def __init__(self, patience=5, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w0fdGzSUy8T9"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, weight_decay = DECAY, momentum = MOMENTUM, nesterov = True)\n",
    "early_stopping = EarlyStopping(patience=PATIENCE, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zvMIxsQ7Y_nd"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "    \n",
    "total_t0 = time.time()\n",
    "\n",
    "weight_class = torch.tensor([1,1.2,1.5,1.5,1.5,1.5, 1.5, 1.2]).to(device)\n",
    "criterion = torch.nn.BCELoss(weight_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MwIP7K2iz5-x",
    "outputId": "23aee926-3d40-4b2a-bdb1-51a3b793baee",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    model.train()   # Important when you are using BatchNorm or Dropout Layers as they work differenlty in testing and training.\n",
    "\n",
    "    train_loss = 0 \n",
    "    train_acc = 0 \n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate((train_dataloader)):\n",
    "\n",
    "        if batch_idx % 10 == 0 and not batch_idx == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(batch_idx, len(train_dataloader), elapsed))\n",
    "\n",
    "        optimizer.zero_grad() \n",
    "\n",
    "        data = data.to(device=device).float()\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        scores = model(data)\n",
    "        scores = torch.sigmoid(scores)\n",
    "\n",
    "        loss = criterion(scores, targets.float())\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        preds = predictions(scores).to(device)\n",
    "        acc = (torch.sum(preds == targets)/(BATCH_SIZE*8))\n",
    "        train_acc += acc\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_dataloader)\n",
    "    train_accuracy = train_acc / len(train_dataloader)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "      for batch_idx, (data, targets) in enumerate((val_dataloader)) :\n",
    "\n",
    "        if batch_idx % 10 == 0 and not batch_idx == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(batch_idx, len(val_dataloader), elapsed))\n",
    "\n",
    "        data = data.to(device=device).float()\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        scores = model(data)\n",
    "        scores = torch.sigmoid(scores)\n",
    "\n",
    "        loss = criterion(scores, targets.float())\n",
    "        val_loss += loss.item()\n",
    "\n",
    "        preds = predictions(scores).to(device)\n",
    "        val_acc += (torch.sum(preds == targets)/(BATCH_SIZE*8))\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    val_accuracy = val_acc / len(val_dataloader)\n",
    "\n",
    "    # wandb.log({'epoch': epoch, 'train_loss': avg_train_loss, 'train_acc': train_accuracy, 'val_loss': avg_val_loss, 'val_acc': val_accuracy})\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], \"f\"Train Loss: {avg_train_loss:.4f}, \"f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], \"f\"Val Loss: {avg_val_loss:.4f}, \"f\"Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    early_stopping(avg_val_loss, model)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        print('-'*60)\n",
    "        break  \n",
    "\n",
    "    print('-'*60)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R2DwJJA1sXti"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"eff_b3_normal.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "model = model.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "test_acc  = 0\n",
    "for batch_idx, (data, targets) in enumerate((test_dataloader)):\n",
    "    data = data.to(device).float()\n",
    "    targets = targets.to(device)\n",
    "    with torch.no_grad():\n",
    "        scores = model(data)\n",
    "        scores = torch.sigmoid(scores)\n",
    "\n",
    "    loss = criterion(scores, targets.float())\n",
    "    test_loss+= loss.item()\n",
    "    preds = predictions(scores).to(device)\n",
    "    test_acc+= (torch.sum(preds == targets)/(BATCH_SIZE*8))\n",
    "\n",
    "avg_test_loss = test_loss/len(test_dataloader)\n",
    "avg_test_acc  = test_acc /len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "avg_test_loss, avg_test_acc.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on preheld testing set\n",
    "\n",
    "|Metric  |Value|\n",
    "|:------:|-----|\n",
    "|Accuracy|0.891|\n",
    "|Loss    |0.330|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.efficientnet_b3(parameters = {'weights': torchvision.models.EfficientNet_B3_Weights.DEFAULT}).to(device)\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "NUM_CLASSES = 8\n",
    "model.classifier[1] = torch.nn.Linear(in_features=num_ftrs, out_features=NUM_CLASSES, bias=True)\n",
    "model.classifier[0] = torch.nn.Dropout(p=0.5, inplace=True)\n",
    "model = model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"eff_b3_normal.pt\"))\n",
    "# Print the model summary\n",
    "# summary(model, (3, 299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "test_csv = pd.read_csv(TEST_CSV)\n",
    "test_csv = test_csv.drop(columns = ['ID', 'Patient Age', 'Patient Sex', 'eye', 'NOT DECISIVE'])\n",
    "test_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "X_test = test_csv['Image'].to_numpy()\n",
    "Y_test = test_csv.drop(['Image'], axis = 1).to_numpy()\n",
    "\n",
    "X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def binary_cross_entropy(y_true, y_pred):\n",
    "    epsilon = 1e-15\n",
    "    y_pred = torch.clamp(y_pred, min = epsilon, max = 1-epsilon)\n",
    "    loss = -(y_true * torch.log(y_pred) + (1 - y_true) * torch.log(1 - y_pred))\n",
    "    mean_loss = torch.mean(loss)\n",
    "    return mean_loss\n",
    "\n",
    "def criterion(y_true_batch, y_pred_batch) :\n",
    "    B = y_true_batch.shape[0]\n",
    "    loss = 0 \n",
    "    for i in range(B) :\n",
    "      loss += binary_cross_entropy(y_true_batch[i], y_pred_batch[i])\n",
    "    return loss/B \n",
    "\n",
    "def predictions(scores) :\n",
    "    \n",
    "    B = scores.shape[0]\n",
    "    predictions = torch.empty(B, NUM_CLASSES)\n",
    "    \n",
    "    for i in range(B) :\n",
    "      pred = torch.empty(NUM_CLASSES,)\n",
    "      for j in range(NUM_CLASSES) : \n",
    "        if(scores[i][j] > 0.5) :\n",
    "          pred[j] = 1\n",
    "        else :\n",
    "          pred[j] = 0\n",
    "      predictions[i] = pred\n",
    "\n",
    "    return predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "weight_class = torch.tensor([1,1.2,1.5,1.5,1.5,1.5, 1.5, 1.2]).to(device)\n",
    "criterion = torch.nn.BCELoss(weight_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "test_dataset = ODIRDataset(X_test, Y_test, IMAGE_FOLDER, transform = None)\n",
    "test_dataloader_preheld = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "model = model.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "test_acc  = 0\n",
    "PREC = torchmetrics.classification.MultilabelPrecision(8, average = 'micro')#, validate_args = False)\n",
    "ACC = torchmetrics.classification.MultilabelAccuracy(8, average = 'micro')#, validate_args = False)\n",
    "REC = torchmetrics.classification.MultilabelRecall(8, average = 'micro')#, validate_args = False)\n",
    "F1_SCORE = torchmetrics.classification.MultilabelF1Score(8, average = 'micro')#, validate_args = False)\n",
    "F_BETA_SCORE = torchmetrics.classification.MultilabelFBetaScore(beta = 0.8, num_classes = 8, num_labels = 8, average = 'micro')#, validate_args = False)\n",
    "KAPPA = torchmetrics.classification.MulticlassCohenKappa(8)#, validate_args = False)\n",
    "AUC = torchmetrics.classification.MultilabelAUROC(8, average = 'micro')#, validate_args = False)\n",
    "\n",
    "for batch_idx, (data, targets) in enumerate((test_dataloader_preheld)):\n",
    "    data = data.to(device).float()\n",
    "    targets = targets.to(device)\n",
    "    with torch.no_grad():\n",
    "        scores = model(data)\n",
    "        scores = torch.sigmoid(scores)\n",
    "    loss = criterion(scores, targets.float())\n",
    "    test_loss+= loss.item()\n",
    "    predicted = predictions(scores).to(device)\n",
    "    test_acc+= (torch.sum(predicted == targets)/(BATCH_SIZE*8))\n",
    "\n",
    "    predicted = predicted.to('cpu')\n",
    "    targets = targets.to('cpu')\n",
    "    PREC(predicted, targets)\n",
    "    ACC(predicted, targets)\n",
    "    REC(predicted, targets)\n",
    "    F1_SCORE(predicted, targets)\n",
    "    F_BETA_SCORE(predicted, targets)\n",
    "    KAPPA(predicted, targets)\n",
    "    AUC(predicted, targets)\n",
    "\n",
    "\n",
    "add_prec = PREC.compute()\n",
    "add_acc = ACC.compute()\n",
    "add_rec = REC.compute()\n",
    "add_f1 = F1_SCORE.compute()\n",
    "add_fbeta = F_BETA_SCORE.compute()\n",
    "add_kappa = KAPPA.compute()\n",
    "add_auc = AUC.compute()\n",
    "\n",
    "avg_test_loss = test_loss/len(test_dataloader_preheld)\n",
    "avg_test_acc  = test_acc /len(test_dataloader_preheld)\n",
    "\n",
    "print(\"Acc: {:3f}\\nPrec: {:3f}\\nRecall: {:.3f}\\nF1-score: {:.3f}\\nF-Beta-score: {:.3f}\\nKappa: {:.3f}\\nAUC: {:.3f}\".format(add_acc, add_prec,add_rec, add_f1, add_fbeta, add_kappa, add_auc))\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "avg_test_loss, avg_test_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.11.3 ('torchnew')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "aae2c75324e7fdf5ebd22146e2daffaa477f8ea149f0e685be4c317c2939a685"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
