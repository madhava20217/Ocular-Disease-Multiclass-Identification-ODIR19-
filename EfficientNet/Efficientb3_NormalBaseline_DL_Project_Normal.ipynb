{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nBOCxp_qHYHH",
    "outputId": "579f5998-7380-4f04-efde-c6d4d2d004f6"
   },
   "outputs": [],
   "source": [
    "#!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "JMOxJ1nqF4SE"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'charset_normalizer' has no attribute 'md__mypyc' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\testing\\lib\\site-packages\\requests\\__init__.py:48\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m RequestsDependencyWarning\n\u001b[0;32m     47\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 48\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mcharset_normalizer\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__ \u001b[39mas\u001b[39;00m charset_normalizer_version\n\u001b[0;32m     49\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[0;32m     50\u001b[0m     charset_normalizer_version \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\testing\\lib\\site-packages\\charset_normalizer\\__init__.py:23\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mCharset-Normalizer\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m~~~~~~~~~~~~~~\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39m:license: MIT, see LICENSE for more details.\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcharset_normalizer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m from_fp, from_path, from_bytes, normalize\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcharset_normalizer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m \u001b[39mimport\u001b[39;00m detect\n\u001b[0;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcharset_normalizer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversion\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__, VERSION\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\testing\\lib\\site-packages\\charset_normalizer\\api.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m     PathLike \u001b[39m=\u001b[39m Union[\u001b[39mstr\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mos.PathLike[str]\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcharset_normalizer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconstant\u001b[39;00m \u001b[39mimport\u001b[39;00m TOO_SMALL_SEQUENCE, TOO_BIG_SEQUENCE, IANA_SUPPORTED\n\u001b[1;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcharset_normalizer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmd\u001b[39;00m \u001b[39mimport\u001b[39;00m mess_ratio\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcharset_normalizer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m CharsetMatches, CharsetMatch\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mwarnings\u001b[39;00m \u001b[39mimport\u001b[39;00m warn\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'charset_normalizer' has no attribute 'md__mypyc' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import logging\n",
    "import gdown\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torchvision.datasets import VOCSegmentation\n",
    "import torchmetrics\n",
    "import torchvision\n",
    "import albumentations as A\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from scipy.io import loadmat\n",
    "from sklearn.manifold import TSNE\n",
    "from torchmetrics.functional.classification import multiclass_accuracy\n",
    "from torchmetrics.classification import MulticlassF1Score, JaccardIndex, MulticlassPrecision, MulticlassRecall, MulticlassAveragePrecision\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6xU3yEKqHMov",
    "outputId": "830e1b8a-a95c-43df-c1f4-a6dfc47a5108"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "    \n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BRIQN1ehjjy_"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "ROOT_DIR = '/content/drive/MyDrive/Project/Datasets/ocular-disease-recognition-odir5k'\n",
    "ROOT_DIR = '../Datasets/ocular-disease-recognition-odir5k/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "264dKYHtkr_t"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "IMAGE_FOLDER = ROOT_DIR + '/preprocessed_images'\n",
    "CSV_PATH = ROOT_DIR + '/dataset_single_eye.csv'\n",
    "TEST_CSV = ROOT_DIR + '/TESTING_dataset_single_eye.csv'\n",
    "\n",
    "TRAIN_RATIO, VAL_RATIO, TEST_RATIO = 0.8, 0.1, 0.1\n",
    "\n",
    "NUM_CLASSES = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: Efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "class ImageResizer:\n",
    "    \n",
    "    def __init__(self, image_width, quality, source_folder, destination_folder, file_name, keep_aspect_ratio):\n",
    "        self.image_width = image_width\n",
    "        self.quality = quality\n",
    "        self.source_folder = source_folder\n",
    "        self.destination_folder= destination_folder\n",
    "        self.file_name = file_name\n",
    "        self.keep_aspect_ration = keep_aspect_ratio\n",
    "\n",
    "    def run(self):\n",
    "\n",
    "        # We load the original file, we resize it to a smaller width and correspondent height and\n",
    "        # also mirror the image when we find a right eye image so they are all left eyes\n",
    "\n",
    "        file = os.path.join(self.source_folder, self.file_name)\n",
    "        img = Image.open(file)\n",
    "\n",
    "        if self.keep_aspect_ration:\n",
    "            width_percentage = (self.image_width / float(img.size[0]))\n",
    "            height_size = int((float(img.size[1]) * float(width_percentage)))\n",
    "            img = img.resize((self.image_width, height_size), Image.ANTIALIAS)\n",
    "        else:\n",
    "            img = img.resize((self.image_width, self.image_width), Image.ANTIALIAS)\n",
    "        if \"right\" in self.file_name:\n",
    "            img.transpose(Image.Transpose.FLIP_LEFT_RIGHT).save(os.path.join(self.destination_folder, self.file_name), optimize=True, quality=self.quality)\n",
    "        else:\n",
    "            img.save(os.path.join(self.destination_folder, self.file_name), optimize=True, quality=self.quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "SRC_PATH = ROOT_DIR + '/preprocessed_images'\n",
    "DEST_PATH = ROOT_DIR + '/inception_preprocessed_images'\n",
    "\n",
    "os.makedirs(DEST_PATH, exist_ok = True)\n",
    "\n",
    "# files = [f for f in os.listdir(SRC_PATH) if os.path.isfile(os.path.join(SRC_PATH, f))]\n",
    "# for file in tqdm(files):\n",
    "#     ImageResizer(image_width = 299, quality = 100, source_folder = SRC_PATH, destination_folder = DEST_PATH, file_name = file, keep_aspect_ratio = False).run()\n",
    "\n",
    "# files = [f for f in os.listdir(SRC_PATH) if not(os.path.isfile(os.path.join(DEST_PATH, f)))]\n",
    "# print(len(files))\n",
    "\n",
    "# for file in tqdm(files):\n",
    "#     ImageResizer(image_width = 299, quality = 100, source_folder = SRC_PATH, destination_folder = DEST_PATH, file_name = file, keep_aspect_ratio = False).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NA2ad5WWnd1n"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Mount Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "id": "a-tNFXrTHAc9",
    "outputId": "cf1acb83-8516-473c-f260-5c621e9dde6b"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "csv = pd.read_csv(CSV_PATH)\n",
    "\n",
    "csv = csv[csv['NOT DECISIVE'] == 0]\n",
    "\n",
    "csv['img_exists'] = csv['Image'].apply(lambda x: os.path.isfile(IMAGE_FOLDER + \"/\" + x))\n",
    "\n",
    "# drop the rows for which the file does not exist\n",
    "csv = csv[csv['img_exists']]\n",
    "\n",
    "csv.drop(columns = ['ID', 'eye', 'Patient Age',\t'Patient Sex', 'NOT DECISIVE', 'img_exists'], inplace = True)\n",
    "csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-bdShfGZqaGv"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# images = [img.split('.', 1)[0] for img in os.listdir(IMAGE_FOLDER) if os.path.isfile(os.path.join(IMAGE_FOLDER, img))]\n",
    "# print(images[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uIFJ65l8Jwno",
    "outputId": "e3405171-c0b8-4fee-b9b4-3ea69fba7484"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "X = csv['Image'].to_numpy()\n",
    "Y = csv.drop(['Image'], axis = 1).to_numpy()\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EoA_pu9vpJJb"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "class ODIRDataset(Dataset) :\n",
    "    \n",
    "    def __init__(self, X, Y, IMG_FOLDER, transform = None) :\n",
    "        \n",
    "        '''\n",
    "        id : list of samples ids as string\n",
    "        '''\n",
    "\n",
    "        self.images = X\n",
    "        self.labels = Y\n",
    "        self.image_dir = IMG_FOLDER\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_path = os.path.join(self.image_dir, self.images[idx])\n",
    "        \n",
    "        #image = Image.open(img_path).convert(\"RGB\")\n",
    "        #hist_image = Image.open(hist_img_path)\n",
    "        image = torchvision.io.read_image(img_path)\n",
    "        #hist_image = torchvision.io.read_image(hist_img_path)\n",
    "\n",
    "        labels = torch.Tensor(self.labels[idx]).long()\n",
    "        t = T.Resize((299,299),interpolation=torchvision.transforms.InterpolationMode.NEAREST)\n",
    "        image = t(image)#.long()\n",
    "    \n",
    "        image = image.numpy()\n",
    "        if(self.transform != None) :\n",
    "            image = np.transpose(image, (1,2,0))\n",
    "            image = self.transform(image = image)['image']\n",
    "#             print(image)\n",
    "            image = np.transpose(image, (2,0,1))\n",
    "          #hist_image = self.transform(hist_image)\n",
    "        image=torch.tensor(image)\n",
    "\n",
    "        #return image, hist_image, labels\n",
    "        return image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wu2AfXqUtb8P"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def train_val_test_split(dataset, train_percent=0.75, val_percent=0.15, test_percent=0.1, seed=None):\n",
    "    \n",
    "    # Given a pytorch Dataset, split it\n",
    "\n",
    "    assert len(X) == len(Y), \"X and Y should have the same length\"\n",
    "    assert round(train_percent + val_percent + test_percent,1) == 1.0, \"Train, validation, and test percentages should add up to 1.0\"\n",
    "\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    train_size = int(train_percent * len(dataset))\n",
    "    val_size = int(val_percent * len(dataset))\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "    # use random_split to split the dataset into train, val, and test sets\n",
    "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lh25UWJhtgH6"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "RANDOM_SEED = 69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qgQPtC7NsPsl"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "ODIR_Dataset = ODIRDataset(X, Y, IMAGE_FOLDER, transform = None)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = train_val_test_split(ODIR_Dataset, TRAIN_RATIO, VAL_RATIO, TEST_RATIO, RANDOM_SEED)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n1MxByrstyYT",
    "outputId": "c8f1e96e-9147-4251-cf37-4ed838592579"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jsT3OwbrnbSV",
    "outputId": "79084279-1119-45d2-900f-2ba84b3fac07"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader))\n",
    "print(len(val_dataloader))\n",
    "print(len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "evgTKEbXt9aS",
    "outputId": "1740856a-c886-459c-d69e-eaab0d3b45fb"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "train_sample, train_label = train_dataset[9]\n",
    "\n",
    "print(train_sample.shape)\n",
    "\n",
    "image_array = np.transpose(train_sample, (1, 2, 0))\n",
    "plt.imshow(image_array)\n",
    "plt.show()\n",
    "\n",
    "# print(train_sample)\n",
    "print(train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfl6bBsqoZPB"
   },
   "source": [
    "### **MODEL ARCHITECTURE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BXZCtaFUofNy"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 8\n",
    "LEARNING_RATE = 0.01\n",
    "DECAY = 1e-6 \n",
    "MOMENTUM = 0.9\n",
    "NUM_EPOCHS = 100\n",
    "PATIENCE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ETKx9rseoGDO",
    "outputId": "8759e154-dc81-41ab-b890-ba401a5798c9"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\n",
    "# model = models.inception_v3(weights=torchvision.models.Inception_V3_Weights.DEFAULT)\n",
    "model = torchvision.models.efficientnet_b3(parameters = {'weights': torchvision.models.EfficientNet_B3_Weights.DEFAULT}).to(device)\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "NUM_CLASSES = 8\n",
    "model.classifier[1] = torch.nn.Linear(in_features=num_ftrs, out_features=NUM_CLASSES, bias=True)\n",
    "model.classifier[0] = torch.nn.Dropout(p=0.5, inplace=True)\n",
    "model = model.to(device)\n",
    "\n",
    "# Freeze the weights of the base model\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# Replace the top layers of the base model\n",
    "# num_features = model.fc.in_features\n",
    "\n",
    "# model.fc = nn.Sequential(\n",
    "#     nn.Linear(num_features, 1024),\n",
    "#     nn.ReLU(inplace=True),\n",
    "#     nn.Linear(1024, NUM_CLASSES),\n",
    "#     nn.Sigmoid()\n",
    "# )\n",
    "\n",
    "# model = model.to(device)\n",
    "\n",
    "# Print the model summary\n",
    "# summary(model, (3, 299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ff0YXiFiH2LR"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def binary_cross_entropy(y_true, y_pred):\n",
    "    epsilon = 1e-15\n",
    "    y_pred = torch.clamp(y_pred, min = epsilon, max = 1-epsilon)\n",
    "    loss = -(y_true * torch.log(y_pred) + (1 - y_true) * torch.log(1 - y_pred))\n",
    "    mean_loss = torch.mean(loss)\n",
    "    return mean_loss\n",
    "\n",
    "def criterion(y_true_batch, y_pred_batch) :\n",
    "    weight_class = torch.tensor([1,1.2,1.5,1.5,1.5,1.5, 1.5, 1.2]).to(device)\n",
    "    criterion = torch.nn.BCELoss(weight_class)\n",
    "    B = y_true_batch.shape[0]\n",
    "    loss = 0 \n",
    "    for i in range(B) :\n",
    "      loss += criterion(y_pred_batch[i],y_true_batch[i])\n",
    "    return loss/B \n",
    "\n",
    "def predictions(scores) :\n",
    "    \n",
    "    B = scores.shape[0]\n",
    "    predictions = torch.empty(B, NUM_CLASSES)\n",
    "    \n",
    "    for i in range(B) :\n",
    "      pred = torch.empty(NUM_CLASSES,)\n",
    "      for j in range(NUM_CLASSES) : \n",
    "        if(scores[i][j] > 0.5) :\n",
    "          pred[j] = 1\n",
    "        else :\n",
    "          pred[j] = 0\n",
    "      predictions[i] = pred\n",
    "\n",
    "    return predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hmCIgQCclmTs"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "class EarlyStopping:\n",
    "\n",
    "    def __init__(self, patience=5, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w0fdGzSUy8T9"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, weight_decay = DECAY, momentum = MOMENTUM, nesterov = True)\n",
    "early_stopping = EarlyStopping(patience=PATIENCE, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zvMIxsQ7Y_nd"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "    \n",
    "total_t0 = time.time()\n",
    "\n",
    "weight_class = torch.tensor([1,1.2,1.5,1.5,1.5,1.5, 1.5, 1.2]).to(device)\n",
    "criterion = torch.nn.BCELoss(weight_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MwIP7K2iz5-x",
    "outputId": "23aee926-3d40-4b2a-bdb1-51a3b793baee",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    model.train()   # Important when you are using BatchNorm or Dropout Layers as they work differenlty in testing and training.\n",
    "\n",
    "    train_loss = 0 \n",
    "    train_acc = 0 \n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate((train_dataloader)):\n",
    "\n",
    "        if batch_idx % 10 == 0 and not batch_idx == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(batch_idx, len(train_dataloader), elapsed))\n",
    "\n",
    "        optimizer.zero_grad() \n",
    "\n",
    "        data = data.to(device=device).float()\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        scores = model(data)\n",
    "        scores = torch.sigmoid(scores)\n",
    "\n",
    "        loss = criterion(scores, targets.float())\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        preds = predictions(scores).to(device)\n",
    "        acc = (torch.sum(preds == targets)/(BATCH_SIZE*8))\n",
    "        train_acc += acc\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_dataloader)\n",
    "    train_accuracy = train_acc / len(train_dataloader)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "      for batch_idx, (data, targets) in enumerate((val_dataloader)) :\n",
    "\n",
    "        if batch_idx % 10 == 0 and not batch_idx == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(batch_idx, len(val_dataloader), elapsed))\n",
    "\n",
    "        data = data.to(device=device).float()\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        scores = model(data)\n",
    "        scores = torch.sigmoid(scores)\n",
    "\n",
    "        loss = criterion(scores, targets.float())\n",
    "        val_loss += loss.item()\n",
    "\n",
    "        preds = predictions(scores).to(device)\n",
    "        val_acc += (torch.sum(preds == targets)/(BATCH_SIZE*8))\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    val_accuracy = val_acc / len(val_dataloader)\n",
    "\n",
    "    # wandb.log({'epoch': epoch, 'train_loss': avg_train_loss, 'train_acc': train_accuracy, 'val_loss': avg_val_loss, 'val_acc': val_accuracy})\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], \"f\"Train Loss: {avg_train_loss:.4f}, \"f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], \"f\"Val Loss: {avg_val_loss:.4f}, \"f\"Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    early_stopping(avg_val_loss, model)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        print('-'*60)\n",
    "        break  \n",
    "\n",
    "    print('-'*60)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R2DwJJA1sXti"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"eff_b3_normal.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "model = model.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "test_acc  = 0\n",
    "for batch_idx, (data, targets) in enumerate((test_dataloader)):\n",
    "    data = data.to(device).float()\n",
    "    targets = targets.to(device)\n",
    "    with torch.no_grad():\n",
    "        scores = model(data)\n",
    "        scores = torch.sigmoid(scores)\n",
    "\n",
    "    loss = criterion(scores, targets.float())\n",
    "    test_loss+= loss.item()\n",
    "    preds = predictions(scores).to(device)\n",
    "    test_acc+= (torch.sum(preds == targets)/(BATCH_SIZE*8))\n",
    "\n",
    "avg_test_loss = test_loss/len(test_dataloader)\n",
    "avg_test_acc  = test_acc /len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "avg_test_loss, avg_test_acc.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on preheld testing set\n",
    "\n",
    "|Metric  |Value|\n",
    "|:------:|-----|\n",
    "|Accuracy|0.891|\n",
    "|Loss    |0.330|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.efficientnet_b3(parameters = {'weights': torchvision.models.EfficientNet_B3_Weights.DEFAULT}).to(device)\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "NUM_CLASSES = 8\n",
    "model.classifier[1] = torch.nn.Linear(in_features=num_ftrs, out_features=NUM_CLASSES, bias=True)\n",
    "model.classifier[0] = torch.nn.Dropout(p=0.5, inplace=True)\n",
    "model = model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"eff_b3_normal.pt\"))\n",
    "# Print the model summary\n",
    "# summary(model, (3, 299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "test_csv = pd.read_csv(TEST_CSV)\n",
    "test_csv = test_csv.drop(columns = ['ID', 'Patient Age', 'Patient Sex', 'eye', 'NOT DECISIVE'])\n",
    "test_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "X_test = test_csv['Image'].to_numpy()\n",
    "Y_test = test_csv.drop(['Image'], axis = 1).to_numpy()\n",
    "\n",
    "X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def binary_cross_entropy(y_true, y_pred):\n",
    "    epsilon = 1e-15\n",
    "    y_pred = torch.clamp(y_pred, min = epsilon, max = 1-epsilon)\n",
    "    loss = -(y_true * torch.log(y_pred) + (1 - y_true) * torch.log(1 - y_pred))\n",
    "    mean_loss = torch.mean(loss)\n",
    "    return mean_loss\n",
    "\n",
    "def criterion(y_true_batch, y_pred_batch) :\n",
    "    B = y_true_batch.shape[0]\n",
    "    loss = 0 \n",
    "    for i in range(B) :\n",
    "      loss += binary_cross_entropy(y_true_batch[i], y_pred_batch[i])\n",
    "    return loss/B \n",
    "\n",
    "def predictions(scores) :\n",
    "    \n",
    "    B = scores.shape[0]\n",
    "    predictions = torch.empty(B, NUM_CLASSES)\n",
    "    \n",
    "    for i in range(B) :\n",
    "      pred = torch.empty(NUM_CLASSES,)\n",
    "      for j in range(NUM_CLASSES) : \n",
    "        if(scores[i][j] > 0.5) :\n",
    "          pred[j] = 1\n",
    "        else :\n",
    "          pred[j] = 0\n",
    "      predictions[i] = pred\n",
    "\n",
    "    return predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "weight_class = torch.tensor([1,1.2,1.5,1.5,1.5,1.5, 1.5, 1.2]).to(device)\n",
    "criterion = torch.nn.BCELoss(weight_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "test_dataset = ODIRDataset(X_test, Y_test, IMAGE_FOLDER, transform = None)\n",
    "test_dataloader_preheld = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "model = model.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "test_acc  = 0\n",
    "PREC = torchmetrics.classification.MultilabelPrecision(8, average = 'micro')#, validate_args = False)\n",
    "ACC = torchmetrics.classification.MultilabelAccuracy(8, average = 'micro')#, validate_args = False)\n",
    "REC = torchmetrics.classification.MultilabelRecall(8, average = 'micro')#, validate_args = False)\n",
    "F1_SCORE = torchmetrics.classification.MultilabelF1Score(8, average = 'micro')#, validate_args = False)\n",
    "F_BETA_SCORE = torchmetrics.classification.MultilabelFBetaScore(beta = 0.8, num_classes = 8, num_labels = 8, average = 'micro')#, validate_args = False)\n",
    "KAPPA = torchmetrics.classification.MulticlassCohenKappa(8)#, validate_args = False)\n",
    "AUC = torchmetrics.classification.MultilabelAUROC(8, average = 'micro')#, validate_args = False)\n",
    "\n",
    "for batch_idx, (data, targets) in enumerate((test_dataloader_preheld)):\n",
    "    data = data.to(device).float()\n",
    "    targets = targets.to(device)\n",
    "    with torch.no_grad():\n",
    "        scores = model(data)\n",
    "        scores = torch.sigmoid(scores)\n",
    "    loss = criterion(scores, targets.float())\n",
    "    test_loss+= loss.item()\n",
    "    predicted = predictions(scores).to(device)\n",
    "    test_acc+= (torch.sum(predicted == targets)/(BATCH_SIZE*8))\n",
    "\n",
    "    predicted = predicted.to('cpu')\n",
    "    targets = targets.to('cpu')\n",
    "    PREC(predicted, targets)\n",
    "    ACC(predicted, targets)\n",
    "    REC(predicted, targets)\n",
    "    F1_SCORE(predicted, targets)\n",
    "    F_BETA_SCORE(predicted, targets)\n",
    "    KAPPA(predicted, targets)\n",
    "    AUC(predicted, targets)\n",
    "\n",
    "\n",
    "add_prec = PREC.compute()\n",
    "add_acc = ACC.compute()\n",
    "add_rec = REC.compute()\n",
    "add_f1 = F1_SCORE.compute()\n",
    "add_fbeta = F_BETA_SCORE.compute()\n",
    "add_kappa = KAPPA.compute()\n",
    "add_auc = AUC.compute()\n",
    "\n",
    "avg_test_loss = test_loss/len(test_dataloader_preheld)\n",
    "avg_test_acc  = test_acc /len(test_dataloader_preheld)\n",
    "\n",
    "print(\"Acc: {:3f}\\nPrec: {:3f}\\nRecall: {:.3f}\\nF1-score: {:.3f}\\nF-Beta-score: {:.3f}\\nKappa: {:.3f}\\nAUC: {:.3f}\".format(add_acc, add_prec,add_rec, add_f1, add_fbeta, add_kappa, add_auc))\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "avg_test_loss, avg_test_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0 ('testing')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n testing ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.10.0 ('testing')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "92e924fb8908865872bfb1f21d222c20d17a33b72f715794630735f5716c8c96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
