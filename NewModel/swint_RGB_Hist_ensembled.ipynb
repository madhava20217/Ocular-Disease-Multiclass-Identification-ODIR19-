{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import logging\n",
    "import gdown\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "from torchvision.datasets import VOCSegmentation\n",
    "import torchmetrics\n",
    "import torchvision\n",
    "import albumentations as A\n",
    "\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as T\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from scipy.io import loadmat\n",
    "from sklearn.manifold import TSNE\n",
    "from torchmetrics.classification import MulticlassF1Score, JaccardIndex, MulticlassPrecision, MulticlassRecall, MulticlassAveragePrecision\n",
    "import pandas as pd\n",
    "from torchinfo import torchinfo\n",
    "\n",
    "from transformers import ConvNextV2Model, BertModel, BertTokenizer, ViTModel, ViTConfig\n",
    "from transformers import AutoTokenizer, AutoModel, RobertaTokenizer, CLIPModel, CLIPTokenizer, CLIPProcessor\n",
    "from transformers import DeiTConfig, DeiTFeatureExtractor, DeiTImageProcessor, DeiTModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "from transformers import AlignModel, AlignProcessor, AlignConfig, AlignVisionConfig, AlignTextConfig\n",
    "from transformers import CLIPModel, CLIPProcessor, CLIPConfig, CLIPTextConfig, CLIPVisionConfig, CLIPImageProcessor\n",
    "\n",
    "from torchmetrics.functional import pairwise_cosine_similarity\n",
    "from torchmetrics.classification import MultilabelAccuracy\n",
    "from transformers import AutoImageProcessor, Swinv2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "    \n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = '../Datasets/ocular-disease-recognition-odir5k/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = ROOT_DIR + 'dataset_single_eye.csv'\n",
    "TEST_CSV = ROOT_DIR + 'TESTING_dataset_single_eye.csv'\n",
    "IMG_PATH = ROOT_DIR + 'preprocessed_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 512])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchvision.io.read_image(IMG_PATH + '0_left.jpg').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_df = pd.read_csv(CSV_PATH)\n",
    "test_df = pd.read_csv(TEST_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(df:pd.DataFrame):\n",
    "    df['Keywords'] = df['Keywords'].str.lower()\n",
    "    df['Keywords'] = df['Keywords'].apply(lambda x: \" \".join(x.split()))\n",
    "    df['Keywords'] = df['Keywords'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '' , x))\n",
    "    return df\n",
    "train_val_df = preprocess_text(train_val_df)\n",
    "test_df = preprocess_text(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_df['Patient Sex'] = train_val_df['Patient Sex'].astype('category').cat.codes\n",
    "test_df['Patient Sex'] = test_df['Patient Sex'].astype('category').cat.codes\n",
    "\n",
    "train_val_df['eye'] = train_val_df['Patient Sex'].astype('category').cat.codes\n",
    "test_df['eye'] = test_df['Patient Sex'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Sex</th>\n",
       "      <th>Image</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>eye</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>G</th>\n",
       "      <th>C</th>\n",
       "      <th>A</th>\n",
       "      <th>H</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "      <th>NOT DECISIVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>970</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>970_right.jpg</td>\n",
       "      <td>cataract</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>127_left.jpg</td>\n",
       "      <td>proliferative diabetic retinopathy，hypertensiv...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>850</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>850_right.jpg</td>\n",
       "      <td>macular epiretinal membrane，moderate non proli...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>37_right.jpg</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4421</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>4421_right.jpg</td>\n",
       "      <td>moderate non proliferative retinopathy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5733</th>\n",
       "      <td>199</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>199_left.jpg</td>\n",
       "      <td>branch retinal vein occlusion</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>516</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>516_right.jpg</td>\n",
       "      <td>moderate non proliferative retinopathy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5735</th>\n",
       "      <td>4603</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>4603_left.jpg</td>\n",
       "      <td>severe nonproliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5736</th>\n",
       "      <td>2132</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>2132_right.jpg</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5737</th>\n",
       "      <td>4487</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>4487_right.jpg</td>\n",
       "      <td>mild nonproliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5738 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Patient Age  Patient Sex           Image  \\\n",
       "0      970           56            0   970_right.jpg   \n",
       "1      127           52            1    127_left.jpg   \n",
       "2      850           68            1   850_right.jpg   \n",
       "3       37           41            1    37_right.jpg   \n",
       "4     4421           59            1  4421_right.jpg   \n",
       "...    ...          ...          ...             ...   \n",
       "5733   199           50            0    199_left.jpg   \n",
       "5734   516           42            1   516_right.jpg   \n",
       "5735  4603           47            0   4603_left.jpg   \n",
       "5736  2132           59            0  2132_right.jpg   \n",
       "5737  4487           55            0  4487_right.jpg   \n",
       "\n",
       "                                               Keywords  eye  N  D  G  C  A  \\\n",
       "0                                              cataract    0  0  0  0  1  0   \n",
       "1     proliferative diabetic retinopathy，hypertensiv...    1  0  1  0  0  0   \n",
       "2     macular epiretinal membrane，moderate non proli...    1  0  1  0  0  0   \n",
       "3                                         normal fundus    1  1  0  0  0  0   \n",
       "4                moderate non proliferative retinopathy    1  0  1  0  0  0   \n",
       "...                                                 ...  ... .. .. .. .. ..   \n",
       "5733                      branch retinal vein occlusion    0  0  0  0  0  0   \n",
       "5734             moderate non proliferative retinopathy    1  0  1  0  0  0   \n",
       "5735                severe nonproliferative retinopathy    0  0  1  0  0  0   \n",
       "5736                                      normal fundus    0  1  0  0  0  0   \n",
       "5737                  mild nonproliferative retinopathy    0  0  1  0  0  0   \n",
       "\n",
       "      H  M  O  NOT DECISIVE  \n",
       "0     0  0  0             0  \n",
       "1     0  0  0             0  \n",
       "2     0  0  0             0  \n",
       "3     0  0  0             0  \n",
       "4     0  0  0             0  \n",
       "...  .. .. ..           ...  \n",
       "5733  0  0  1             0  \n",
       "5734  0  0  0             0  \n",
       "5735  0  0  0             0  \n",
       "5736  0  0  0             0  \n",
       "5737  0  0  0             0  \n",
       "\n",
       "[5738 rows x 15 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(train_val_df['Keywords'].apply(lambda x: len(x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4877, 861)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, val_df = train_test_split(train_val_df, test_size = 0.15, random_state= 123456)\n",
    "len(train_df), len(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (256, 256)\n",
    "\n",
    "rescale_transform = torchvision.transforms.Compose([\n",
    "    #torchvision.transforms.CenterCrop(IMG_SIZE),\n",
    "    torchvision.transforms.Resize(IMG_SIZE, antialias = False, interpolation = torchvision.transforms.InterpolationMode.NEAREST),\n",
    "    torchvision.transforms.Normalize(\n",
    "        timm.data.constants.IMAGENET_DEFAULT_MEAN,\n",
    "        timm.data.constants.IMAGENET_DEFAULT_STD\n",
    "    )\n",
    "])\n",
    "\n",
    "augmentation = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.PILToTensor(),\n",
    "    torchvision.transforms.Resize(IMG_SIZE, antialias = False, interpolation = torchvision.transforms.InterpolationMode.NEAREST),\n",
    "#     torchvision.transforms.RandomHorizontalFlip(p = 0.5),\n",
    "#     torchvision.transforms.RandomVerticalFlip(p= 0.5),\n",
    "    #torchvision.transforms.RandomRotation(90)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56,  0],\n",
       "       [52,  1],\n",
       "       [68,  1],\n",
       "       ...,\n",
       "       [47,  0],\n",
       "       [59,  0],\n",
       "       [55,  0]], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.c_[train_val_df['Patient Age'].to_numpy(), train_val_df['Patient Sex'].to_numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODIRDataset(Dataset) :\n",
    "    def __init__(self, df, IMG_FOLDER, extractor = rescale_transform, augmentation = None) :\n",
    "        '''\n",
    "        id : list of samples ids as string\n",
    "        '''\n",
    "        #self.text = [tokenizer(text = x, padding = 'max_length', max_length = 40, truncation = True, return_tensors = 'pt') for x in df['Keywords']]\n",
    "        self.images = [Image.open(IMG_PATH + x).convert(\"RGB\") for x in df['Image']]\n",
    "        processor = AutoImageProcessor.from_pretrained(\"microsoft/swinv2-tiny-patch4-window8-256\")\n",
    "        self.images = [processor(x, return_tensors=\"pt\") for x in tqdm(self.images)]\n",
    "        sex = df['Patient Age'].to_numpy()\n",
    "        age = (df['Patient Age']/df['Patient Age'].max()).to_numpy()\n",
    "        self.feats = torch.tensor(np.c_[sex, age], requires_grad= True)\n",
    "        self.labels = torch.tensor(df[['N', 'D', 'G', 'C', 'A', 'H', 'M', 'O']].to_numpy()).float()\n",
    "        self.img_dir = [IMG_PATH + x for x in df['Image']]\n",
    "\n",
    "        self.augmentation = augmentation\n",
    "\n",
    "#         self.images = [extractor(torchvision.io.read_image(x)/255.0) for x in self.img_dir]\n",
    "        #self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        batch_imgs = self.images[idx]\n",
    "#         if(self.augmentation is not None):\n",
    "#             batch_imgs = self.augmentation(batch_imgs)\n",
    "        return batch_imgs, self.feats[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = ODIRDataset(train_df, IMG_PATH, augmentation = augmentation)\n",
    "# val_dataset   = ODIRDataset(val_df, IMG_PATH)\n",
    "# test_dataset  = ODIRDataset(test_df, IMG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"datasets.trch\", 'wb') as f:\n",
    "#     torch.save([train_dataset, val_dataset, test_dataset], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets.trch\", 'rb') as f:\n",
    "    train_dataset, val_dataset, test_dataset = torch.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.augmentation = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size= BATCH_SIZE, shuffle = True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size = BATCH_SIZE)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size= BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinTv2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.base = Swinv2Model.from_pretrained(\"microsoft/swinv2-tiny-patch4-window8-256\")\n",
    "        self.base.pooler = nn.AdaptiveAvgPool1d(output_size=1)\n",
    "        self.fc = nn.Linear(768+2, 1000)\n",
    "        self.img_head = nn.Linear(1000, 8)\n",
    "\n",
    "    \n",
    "    def forward(self, pixel_values, add_info):\n",
    "        pixel_values = pixel_values['pixel_values']\n",
    "        pixel_values = pixel_values.squeeze(1)\n",
    "        out = self.base(pixel_values)['pooler_output']\n",
    "        out = torch.hstack([out, add_info])\n",
    "        out = F.relu(self.fc(out))\n",
    "        out = self.img_head(out)\n",
    "\n",
    "        out = F.sigmoid(out)\n",
    "        return out#, img_outs, txt_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/swinv2-tiny-patch4-window8-256 were not used when initializing Swinv2Model: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing Swinv2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Swinv2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model= SwinTv2().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "\n",
    "    def __init__(self, patience=5, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "early_stopping_rgb = EarlyStopping(patience=4, verbose=True, path = 'finetuned_swint_rgb.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:43<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.2976, acc img: 0.8520\n",
      "Epoch [1/10], Val Loss: 0.2215, acc img: 0.9003\n",
      "Validation loss decreased (inf --> 0.006923).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:41<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Train Loss: 0.2003, acc img: 0.9057\n",
      "Epoch [2/10], Val Loss: 0.1968, acc img: 0.9090\n",
      "Validation loss decreased (0.006923 --> 0.006149).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:42<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Train Loss: 0.1739, acc img: 0.9180\n",
      "Epoch [3/10], Val Loss: 0.1865, acc img: 0.9157\n",
      "Validation loss decreased (0.006149 --> 0.005829).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:41<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Train Loss: 0.1544, acc img: 0.9280\n",
      "Epoch [4/10], Val Loss: 0.1735, acc img: 0.9223\n",
      "Validation loss decreased (0.005829 --> 0.005421).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:42<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Train Loss: 0.1374, acc img: 0.9360\n",
      "Epoch [5/10], Val Loss: 0.1802, acc img: 0.9135\n",
      "EarlyStopping counter: 1 out of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:42<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Train Loss: 0.1153, acc img: 0.9484\n",
      "Epoch [6/10], Val Loss: 0.1776, acc img: 0.9204\n",
      "EarlyStopping counter: 2 out of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:42<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Train Loss: 0.0927, acc img: 0.9593\n",
      "Epoch [7/10], Val Loss: 0.1951, acc img: 0.9165\n",
      "EarlyStopping counter: 3 out of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:42<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Train Loss: 0.0696, acc img: 0.9703\n",
      "Epoch [8/10], Val Loss: 0.2122, acc img: 0.9155\n",
      "EarlyStopping counter: 4 out of 4\n",
      "Early stopping\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "val_loss = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "weights = torch.tensor([0.5, 1., 1.25, 1.25, 1.25, 1.3, 1.25, .9]).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-5)\n",
    "train_img_acc = MultilabelAccuracy(8, average = 'micro').to(device)\n",
    "val_img_acc = MultilabelAccuracy(8, average = 'micro').to(device)\n",
    "\n",
    "img_loss_fn = nn.BCELoss(weights)\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch_num in range(EPOCHS):\n",
    "\n",
    "  total_acc_train = 0\n",
    "  total_loss_train = 0\n",
    "\n",
    "  for train_image, train_metadata, train_label in tqdm(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        train_label = train_label.to(device)\n",
    "        train_image = train_image.to(device)\n",
    "\n",
    "        train_metadata = train_metadata.to(device).float()\n",
    "      \n",
    "\n",
    "        output = model(train_image, train_metadata)\n",
    "\n",
    "        batch_loss = img_loss_fn(output, train_label)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss_train += batch_loss.item()\n",
    "      \n",
    "        train_img_acc(output, train_label)\n",
    "\n",
    "  total_loss_val = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "      #Validation\n",
    "      for val_image, val_metadata, val_label in val_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        val_label = val_label.to(device)\n",
    "        val_image = val_image.to(device)\n",
    "        val_metadata = val_metadata.to(device).float()\n",
    "      \n",
    "\n",
    "        output = model(val_image, val_metadata)\n",
    "\n",
    "        batch_loss = img_loss_fn(output, val_label)\n",
    "        total_loss_val += batch_loss.item()\n",
    "        val_img_acc(output, val_label)\n",
    "              \n",
    "      \n",
    "  avg_train_loss = total_loss_train/len(train_df)\n",
    "\n",
    "  avg_val_loss = total_loss_val/len(val_df)\n",
    "\n",
    "\n",
    "  print(\"Epoch [{}/{}], Train Loss: {:.4f}, acc img: {:.4f}\".format(epoch_num+1, EPOCHS, avg_train_loss*BATCH_SIZE, train_img_acc.compute()))\n",
    "  print(\"Epoch [{}/{}], Val Loss: {:.4f}, acc img: {:.4f}\".format(epoch_num+1, EPOCHS, avg_val_loss*BATCH_SIZE, val_img_acc.compute()))\n",
    "  early_stopping_rgb(avg_val_loss, model)\n",
    "\n",
    "  if early_stopping_rgb.early_stop:\n",
    "      print(\"Early stopping\")\n",
    "      print('-'*60)\n",
    "      break\n",
    "\n",
    "  train_acc.append(train_img_acc.compute())\n",
    "  val_acc.append(val_img_acc.compute())\n",
    "  train_loss.append(avg_train_loss)\n",
    "  val_loss.append(avg_val_loss)\n",
    "  train_img_acc.reset()\n",
    "  val_img_acc.reset()\n",
    "\n",
    "  torch.save(model.state_dict(), './' + 'checkpoint_swint_rgb' + '.pt' )\n",
    "\n",
    "#torch.save(model.state_dict(), './' + 'finetuned_swint_rgb' + '.pt' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_t = [x.item() for x in train_acc] \n",
    "ac_v = [x.item() for x in val_acc] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2cad9e67010>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize = (12, 6))\n",
    "ax[0].plot(range(len(train_acc)), ac_t, label = 'Train Accuracy')\n",
    "ax[0].plot(range(len(train_acc)), ac_v, label = 'Val Accuracy')\n",
    "ax[0].set_title(\"Accuracy vs Epochs\")\n",
    "ax[0].legend(loc = 'upper left')\n",
    "\n",
    "ax[1].plot(range(len(train_acc)), train_loss, label = 'Train Loss')\n",
    "ax[1].plot(range(len(train_acc)), val_loss, label = 'Val Loss')\n",
    "ax[1].set_title(\"Loss vs Epochs\")\n",
    "ax[1].legend(loc = 'upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"finetuned_swint_rgb.pt\", 'rb') as f:\n",
    "    model.load_state_dict(torch.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:02<00:00,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.913793\n",
      "Prec: 0.701219\n",
      "Recall: 0.541\n",
      "F1-score: 0.611\n",
      "F-Beta-score: 0.628\n",
      "Kappa: 0.000\n",
      "AUC: 0.938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#criterion = nn.BCELoss(torch.tensor([0.5, 1, 5, 5, 5, 6, 5, 1]).float().to(device))\n",
    "\n",
    "test_loss = 0\n",
    "test_acc  = 0\n",
    "\n",
    "AVERAGING = 'micro'\n",
    "PREC = torchmetrics.classification.MultilabelPrecision(8, average = AVERAGING).to(device)#, validate_args = False)\n",
    "ACC = torchmetrics.classification.MultilabelAccuracy(8, average = AVERAGING).to(device)#, validate_args = False)\n",
    "REC = torchmetrics.classification.MultilabelRecall(8, average = AVERAGING).to(device)#, validate_args = False)\n",
    "F1_SCORE = torchmetrics.classification.MultilabelF1Score(8, average = AVERAGING).to(device)#, validate_args = False)\n",
    "F_BETA_SCORE = torchmetrics.classification.MultilabelFBetaScore(beta = 0.8, num_classes = 8, num_labels = 8, average = AVERAGING).to(device)#, validate_args = False)\n",
    "KAPPA = torchmetrics.classification.MulticlassCohenKappa(8).to(device)#, validate_args = False)\n",
    "AUC = torchmetrics.classification.MultilabelAUROC(8, average = AVERAGING).to(device)#, validate_args = False)\n",
    "\n",
    "for train_image, train_metadata, train_label in tqdm(test_dataloader): \n",
    "    with torch.no_grad():\n",
    "        optimizer.zero_grad()\n",
    "        train_label = train_label.to(device)\n",
    "        train_image = train_image.to(device)\n",
    "        train_metadata = train_metadata.to(device).float()\n",
    "      \n",
    "\n",
    "        predictions = model(train_image, train_metadata)\n",
    "\n",
    "\n",
    "        train_label = train_label.long()\n",
    "        PREC(predictions, train_label)\n",
    "        ACC(predictions, train_label)\n",
    "        REC(predictions, train_label)\n",
    "        F1_SCORE(predictions, train_label)\n",
    "        F_BETA_SCORE(predictions, train_label)\n",
    "        KAPPA(predictions, train_label)\n",
    "        AUC(predictions, train_label)\n",
    "\n",
    "\n",
    "add_prec = PREC.compute()\n",
    "add_acc = ACC.compute()\n",
    "add_rec = REC.compute()\n",
    "add_f1 = F1_SCORE.compute()\n",
    "add_fbeta = F_BETA_SCORE.compute()\n",
    "add_kappa = KAPPA.compute()\n",
    "add_auc = AUC.compute()\n",
    "\n",
    "avg_test_loss = test_loss/len(test_df)*BATCH_SIZE\n",
    "avg_test_acc  = test_acc /len(test_df)\n",
    "\n",
    "print(\"Acc: {:3f}\\nPrec: {:3f}\\nRecall: {:.3f}\\nF1-score: {:.3f}\\nF-Beta-score: {:.3f}\\nKappa: {:.3f}\\nAUC: {:.3f}\".format(add_acc, add_prec,add_rec, add_f1, add_fbeta, add_kappa, add_auc))\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = ROOT_DIR + 'dataset_single_eye.csv'\n",
    "TEST_CSV = ROOT_DIR + 'TESTING_dataset_single_eye.csv'\n",
    "IMG_PATH = ROOT_DIR + 'preprocessed_histeq_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 512])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchvision.io.read_image(IMG_PATH + '0_left.jpg').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_df = pd.read_csv(CSV_PATH)\n",
    "test_df = pd.read_csv(TEST_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(df:pd.DataFrame):\n",
    "    df['Keywords'] = df['Keywords'].str.lower()\n",
    "    df['Keywords'] = df['Keywords'].apply(lambda x: \" \".join(x.split()))\n",
    "    df['Keywords'] = df['Keywords'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '' , x))\n",
    "    return df\n",
    "train_val_df = preprocess_text(train_val_df)\n",
    "test_df = preprocess_text(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_df['Patient Sex'] = train_val_df['Patient Sex'].astype('category').cat.codes\n",
    "test_df['Patient Sex'] = test_df['Patient Sex'].astype('category').cat.codes\n",
    "\n",
    "train_val_df['eye'] = train_val_df['Patient Sex'].astype('category').cat.codes\n",
    "test_df['eye'] = test_df['Patient Sex'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Sex</th>\n",
       "      <th>Image</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>eye</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>G</th>\n",
       "      <th>C</th>\n",
       "      <th>A</th>\n",
       "      <th>H</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "      <th>NOT DECISIVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>970</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>970_right.jpg</td>\n",
       "      <td>cataract</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>127_left.jpg</td>\n",
       "      <td>proliferative diabetic retinopathy，hypertensiv...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>850</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>850_right.jpg</td>\n",
       "      <td>macular epiretinal membrane，moderate non proli...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>37_right.jpg</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4421</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>4421_right.jpg</td>\n",
       "      <td>moderate non proliferative retinopathy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5733</th>\n",
       "      <td>199</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>199_left.jpg</td>\n",
       "      <td>branch retinal vein occlusion</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>516</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>516_right.jpg</td>\n",
       "      <td>moderate non proliferative retinopathy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5735</th>\n",
       "      <td>4603</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>4603_left.jpg</td>\n",
       "      <td>severe nonproliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5736</th>\n",
       "      <td>2132</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>2132_right.jpg</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5737</th>\n",
       "      <td>4487</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>4487_right.jpg</td>\n",
       "      <td>mild nonproliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5738 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Patient Age  Patient Sex           Image  \\\n",
       "0      970           56            0   970_right.jpg   \n",
       "1      127           52            1    127_left.jpg   \n",
       "2      850           68            1   850_right.jpg   \n",
       "3       37           41            1    37_right.jpg   \n",
       "4     4421           59            1  4421_right.jpg   \n",
       "...    ...          ...          ...             ...   \n",
       "5733   199           50            0    199_left.jpg   \n",
       "5734   516           42            1   516_right.jpg   \n",
       "5735  4603           47            0   4603_left.jpg   \n",
       "5736  2132           59            0  2132_right.jpg   \n",
       "5737  4487           55            0  4487_right.jpg   \n",
       "\n",
       "                                               Keywords  eye  N  D  G  C  A  \\\n",
       "0                                              cataract    0  0  0  0  1  0   \n",
       "1     proliferative diabetic retinopathy，hypertensiv...    1  0  1  0  0  0   \n",
       "2     macular epiretinal membrane，moderate non proli...    1  0  1  0  0  0   \n",
       "3                                         normal fundus    1  1  0  0  0  0   \n",
       "4                moderate non proliferative retinopathy    1  0  1  0  0  0   \n",
       "...                                                 ...  ... .. .. .. .. ..   \n",
       "5733                      branch retinal vein occlusion    0  0  0  0  0  0   \n",
       "5734             moderate non proliferative retinopathy    1  0  1  0  0  0   \n",
       "5735                severe nonproliferative retinopathy    0  0  1  0  0  0   \n",
       "5736                                      normal fundus    0  1  0  0  0  0   \n",
       "5737                  mild nonproliferative retinopathy    0  0  1  0  0  0   \n",
       "\n",
       "      H  M  O  NOT DECISIVE  \n",
       "0     0  0  0             0  \n",
       "1     0  0  0             0  \n",
       "2     0  0  0             0  \n",
       "3     0  0  0             0  \n",
       "4     0  0  0             0  \n",
       "...  .. .. ..           ...  \n",
       "5733  0  0  1             0  \n",
       "5734  0  0  0             0  \n",
       "5735  0  0  0             0  \n",
       "5736  0  0  0             0  \n",
       "5737  0  0  0             0  \n",
       "\n",
       "[5738 rows x 15 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(train_val_df['Keywords'].apply(lambda x: len(x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4877, 861)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, val_df = train_test_split(train_val_df, test_size = 0.15, random_state= 123456)\n",
    "len(train_df), len(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "rescale_transform = torchvision.transforms.Compose([\n",
    "    #torchvision.transforms.CenterCrop(IMG_SIZE),\n",
    "    torchvision.transforms.Resize(IMG_SIZE, antialias = False, interpolation = torchvision.transforms.InterpolationMode.NEAREST),\n",
    "    torchvision.transforms.Normalize(\n",
    "        timm.data.constants.IMAGENET_DEFAULT_MEAN,\n",
    "        timm.data.constants.IMAGENET_DEFAULT_STD\n",
    "    )\n",
    "])\n",
    "\n",
    "augmentation = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.PILToTensor(),\n",
    "    torchvision.transforms.Resize(IMG_SIZE, antialias = False, interpolation = torchvision.transforms.InterpolationMode.NEAREST),\n",
    "#     torchvision.transforms.RandomHorizontalFlip(p = 0.5),\n",
    "#     torchvision.transforms.RandomVerticalFlip(p= 0.5),\n",
    "    #torchvision.transforms.RandomRotation(90)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56,  0],\n",
       "       [52,  1],\n",
       "       [68,  1],\n",
       "       ...,\n",
       "       [47,  0],\n",
       "       [59,  0],\n",
       "       [55,  0]], dtype=int64)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.c_[train_val_df['Patient Age'].to_numpy(), train_val_df['Patient Sex'].to_numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODIRDataset(Dataset) :\n",
    "    def __init__(self, df, IMG_FOLDER, extractor = rescale_transform, augmentation = None) :\n",
    "        '''\n",
    "        id : list of samples ids as string\n",
    "        '''\n",
    "        #self.text = [tokenizer(text = x, padding = 'max_length', max_length = 40, truncation = True, return_tensors = 'pt') for x in df['Keywords']]\n",
    "        self.images = [Image.open(IMG_PATH + x).convert(\"RGB\") for x in df['Image']]\n",
    "        processor = AutoImageProcessor.from_pretrained(\"microsoft/swinv2-tiny-patch4-window8-256\")\n",
    "        self.images = [processor(x, return_tensors=\"pt\") for x in self.images]\n",
    "        sex = df['Patient Age'].to_numpy()\n",
    "        age = (df['Patient Age']/df['Patient Age'].max()).to_numpy()\n",
    "        self.feats = torch.tensor(np.c_[sex, age], requires_grad= True)\n",
    "        self.labels = torch.tensor(df[['N', 'D', 'G', 'C', 'A', 'H', 'M', 'O']].to_numpy()).float()\n",
    "        self.img_dir = [IMG_PATH + x for x in df['Image']]\n",
    "\n",
    "        self.augmentation = augmentation\n",
    "\n",
    "#         self.images = [extractor(torchvision.io.read_image(x)/255.0) for x in self.img_dir]\n",
    "        #self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        batch_imgs = self.images[idx]\n",
    "#         if(self.augmentation is not None):\n",
    "#             batch_imgs = self.augmentation(batch_imgs)\n",
    "        return batch_imgs, self.feats[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = ODIRDataset(train_df, IMG_PATH, augmentation = augmentation)\n",
    "# val_dataset   = ODIRDataset(val_df, IMG_PATH)\n",
    "# test_dataset  = ODIRDataset(test_df, IMG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"datasets_hist.trch\", 'wb') as f:\n",
    "#     torch.save([train_dataset, val_dataset, test_dataset], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets_hist.trch\", 'rb') as f:\n",
    "    train_dataset, val_dataset, test_dataset = torch.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size= BATCH_SIZE, shuffle = True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size = BATCH_SIZE)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size= BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinTv2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.base = Swinv2Model.from_pretrained(\"microsoft/swinv2-tiny-patch4-window8-256\")\n",
    "        self.base.pooler = nn.AdaptiveAvgPool1d(output_size=1)\n",
    "        self.fc = nn.Linear(768+2, 1000)\n",
    "        self.img_head = nn.Linear(1000, 8)\n",
    "\n",
    "    \n",
    "    def forward(self, pixel_values, add_info):\n",
    "        pixel_values = pixel_values['pixel_values']\n",
    "        pixel_values = pixel_values.squeeze(1)\n",
    "        out = self.base(pixel_values)['pooler_output']\n",
    "        out = torch.hstack([out, add_info])\n",
    "        out = F.relu(self.fc(out))\n",
    "        out = self.img_head(out)\n",
    "\n",
    "        out = F.sigmoid(out)\n",
    "        return out#, img_outs, txt_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/swinv2-tiny-patch4-window8-256 were not used when initializing Swinv2Model: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing Swinv2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Swinv2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model= SwinTv2().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "\n",
    "    def __init__(self, patience=5, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "early_stopping = EarlyStopping(patience=4, verbose=True, path = 'finetuned_swint_hist.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:50<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.2916, acc img: 0.8645\n",
      "Epoch [1/10], Val Loss: 0.2304, acc img: 0.8939\n",
      "Validation loss decreased (inf --> 0.007200).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:51<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Train Loss: 0.2061, acc img: 0.9042\n",
      "Epoch [2/10], Val Loss: 0.1996, acc img: 0.9106\n",
      "Validation loss decreased (0.007200 --> 0.006237).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:52<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Train Loss: 0.1811, acc img: 0.9165\n",
      "Epoch [3/10], Val Loss: 0.1891, acc img: 0.9152\n",
      "Validation loss decreased (0.006237 --> 0.005908).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:52<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Train Loss: 0.1596, acc img: 0.9261\n",
      "Epoch [4/10], Val Loss: 0.1889, acc img: 0.9116\n",
      "Validation loss decreased (0.005908 --> 0.005902).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:49<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Train Loss: 0.1420, acc img: 0.9354\n",
      "Epoch [5/10], Val Loss: 0.1831, acc img: 0.9164\n",
      "Validation loss decreased (0.005902 --> 0.005722).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:49<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Train Loss: 0.1222, acc img: 0.9451\n",
      "Epoch [6/10], Val Loss: 0.1854, acc img: 0.9181\n",
      "EarlyStopping counter: 1 out of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:52<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Train Loss: 0.0984, acc img: 0.9584\n",
      "Epoch [7/10], Val Loss: 0.1972, acc img: 0.9165\n",
      "EarlyStopping counter: 2 out of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [01:00<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Train Loss: 0.0739, acc img: 0.9705\n",
      "Epoch [8/10], Val Loss: 0.2107, acc img: 0.9191\n",
      "EarlyStopping counter: 3 out of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:56<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Train Loss: 0.0504, acc img: 0.9824\n",
      "Epoch [9/10], Val Loss: 0.2413, acc img: 0.9148\n",
      "EarlyStopping counter: 4 out of 4\n",
      "Early stopping\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-5)\n",
    "train_img_acc = MultilabelAccuracy(8, average = 'micro').to(device)\n",
    "val_img_acc = MultilabelAccuracy(8, average = 'micro').to(device)\n",
    "\n",
    "img_loss_fn = nn.BCELoss(weights)\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch_num in range(EPOCHS):\n",
    "\n",
    "  total_acc_train = 0\n",
    "  total_loss_train = 0\n",
    "\n",
    "  for train_image, train_metadata, train_label in tqdm(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        train_label = train_label.to(device)\n",
    "        train_image = train_image.to(device)\n",
    "        train_metadata = train_metadata.to(device).float()\n",
    "      \n",
    "\n",
    "        output = model(train_image, train_metadata)\n",
    "\n",
    "        batch_loss = img_loss_fn(output, train_label)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss_train += batch_loss.item()\n",
    "      \n",
    "        train_img_acc(output, train_label)\n",
    "\n",
    "  total_loss_val = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "      #Validation\n",
    "      for val_image, val_metadata, val_label in val_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        val_label = val_label.to(device)\n",
    "        val_image = val_image.to(device)\n",
    "        val_metadata = val_metadata.to(device).float()\n",
    "      \n",
    "\n",
    "        output = model(val_image, val_metadata)\n",
    "\n",
    "        batch_loss = img_loss_fn(output, val_label)\n",
    "        total_loss_val += batch_loss.item()\n",
    "        val_img_acc(output, val_label)\n",
    "              \n",
    "      \n",
    "  avg_train_loss = total_loss_train/len(train_df)\n",
    "\n",
    "  avg_val_loss = total_loss_val/len(val_df)\n",
    "\n",
    "\n",
    "  print(\"Epoch [{}/{}], Train Loss: {:.4f}, acc img: {:.4f}\".format(epoch_num+1, EPOCHS, avg_train_loss*BATCH_SIZE, train_img_acc.compute()))\n",
    "  print(\"Epoch [{}/{}], Val Loss: {:.4f}, acc img: {:.4f}\".format(epoch_num+1, EPOCHS, avg_val_loss*BATCH_SIZE, val_img_acc.compute()))\n",
    "  early_stopping(avg_val_loss, model)\n",
    "\n",
    "  if early_stopping.early_stop:\n",
    "      print(\"Early stopping\")\n",
    "      print('-'*60)\n",
    "      break\n",
    "  train_img_acc.reset()\n",
    "  val_img_acc.reset()\n",
    "\n",
    "  #torch.save(model.state_dict(), './' + 'checkpoint_swint_hist' + '.pt' )\n",
    "\n",
    "#torch.save(model.state_dict(), './' + 'finetuned_swint_hist' + '.pt' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"finetuned_swint_hist.pt\", 'rb') as f:\n",
    "    model.load_state_dict(torch.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:05<00:00,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.913401\n",
      "Prec: 0.697581\n",
      "Recall: 0.542\n",
      "F1-score: 0.610\n",
      "F-Beta-score: 0.627\n",
      "Kappa: 0.000\n",
      "AUC: 0.932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#criterion = nn.BCELoss(torch.tensor([0.5, 1, 5, 5, 5, 6, 5, 1]).float().to(device))\n",
    "\n",
    "test_loss = 0\n",
    "test_acc  = 0\n",
    "\n",
    "AVERAGING = 'micro'\n",
    "PREC = torchmetrics.classification.MultilabelPrecision(8, average = AVERAGING).to(device)#, validate_args = False)\n",
    "ACC = torchmetrics.classification.MultilabelAccuracy(8, average = AVERAGING).to(device)#, validate_args = False)\n",
    "REC = torchmetrics.classification.MultilabelRecall(8, average = AVERAGING).to(device)#, validate_args = False)\n",
    "F1_SCORE = torchmetrics.classification.MultilabelF1Score(8, average = AVERAGING).to(device)#, validate_args = False)\n",
    "F_BETA_SCORE = torchmetrics.classification.MultilabelFBetaScore(beta = 0.8, num_classes = 8, num_labels = 8, average = AVERAGING).to(device)#, validate_args = False)\n",
    "KAPPA = torchmetrics.classification.MulticlassCohenKappa(8).to(device)#, validate_args = False)\n",
    "AUC = torchmetrics.classification.MultilabelAUROC(8, average = AVERAGING).to(device)#, validate_args = False)\n",
    "\n",
    "for train_image, train_metadata, train_label in tqdm(test_dataloader): \n",
    "    with torch.no_grad():\n",
    "        optimizer.zero_grad()\n",
    "        train_label = train_label.to(device)\n",
    "        train_image = train_image.to(device)\n",
    "        train_metadata = train_metadata.to(device).float()\n",
    "      \n",
    "\n",
    "        predictions = model(train_image, train_metadata)\n",
    "\n",
    "\n",
    "        train_label = train_label.long()\n",
    "        PREC(predictions, train_label)\n",
    "        ACC(predictions, train_label)\n",
    "        REC(predictions, train_label)\n",
    "        F1_SCORE(predictions, train_label)\n",
    "        F_BETA_SCORE(predictions, train_label)\n",
    "        KAPPA(predictions, train_label)\n",
    "        AUC(predictions, train_label)\n",
    "\n",
    "\n",
    "add_prec = PREC.compute()\n",
    "add_acc = ACC.compute()\n",
    "add_rec = REC.compute()\n",
    "add_f1 = F1_SCORE.compute()\n",
    "add_fbeta = F_BETA_SCORE.compute()\n",
    "add_kappa = KAPPA.compute()\n",
    "add_auc = AUC.compute()\n",
    "\n",
    "avg_test_loss = test_loss/len(test_df)*BATCH_SIZE\n",
    "avg_test_acc  = test_acc /len(test_df)\n",
    "\n",
    "print(\"Acc: {:3f}\\nPrec: {:3f}\\nRecall: {:.3f}\\nF1-score: {:.3f}\\nF-Beta-score: {:.3f}\\nKappa: {:.3f}\\nAUC: {:.3f}\".format(add_acc, add_prec,add_rec, add_f1, add_fbeta, add_kappa, add_auc))\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENSEMBLE STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = ROOT_DIR + 'dataset_single_eye.csv'\n",
    "TEST_CSV = ROOT_DIR + 'TESTING_dataset_single_eye.csv'\n",
    "IMG_PATH = ROOT_DIR + 'preprocessed_images/'\n",
    "HIST_IMG_PATH = ROOT_DIR + 'preprocessed_histeq_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 512])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchvision.io.read_image(IMG_PATH + '0_left.jpg').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_df = pd.read_csv(CSV_PATH)\n",
    "test_df = pd.read_csv(TEST_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(df:pd.DataFrame):\n",
    "    df['Keywords'] = df['Keywords'].str.lower()\n",
    "    df['Keywords'] = df['Keywords'].apply(lambda x: \" \".join(x.split()))\n",
    "    df['Keywords'] = df['Keywords'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '' , x))\n",
    "    return df\n",
    "train_val_df = preprocess_text(train_val_df)\n",
    "test_df = preprocess_text(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_df['Patient Sex'] = train_val_df['Patient Sex'].astype('category').cat.codes\n",
    "test_df['Patient Sex'] = test_df['Patient Sex'].astype('category').cat.codes\n",
    "\n",
    "train_val_df['eye'] = train_val_df['Patient Sex'].astype('category').cat.codes\n",
    "test_df['eye'] = test_df['Patient Sex'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Sex</th>\n",
       "      <th>Image</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>eye</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>G</th>\n",
       "      <th>C</th>\n",
       "      <th>A</th>\n",
       "      <th>H</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "      <th>NOT DECISIVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>970</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>970_right.jpg</td>\n",
       "      <td>cataract</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>127_left.jpg</td>\n",
       "      <td>proliferative diabetic retinopathy，hypertensiv...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>850</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>850_right.jpg</td>\n",
       "      <td>macular epiretinal membrane，moderate non proli...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>37_right.jpg</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4421</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>4421_right.jpg</td>\n",
       "      <td>moderate non proliferative retinopathy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5733</th>\n",
       "      <td>199</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>199_left.jpg</td>\n",
       "      <td>branch retinal vein occlusion</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>516</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>516_right.jpg</td>\n",
       "      <td>moderate non proliferative retinopathy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5735</th>\n",
       "      <td>4603</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>4603_left.jpg</td>\n",
       "      <td>severe nonproliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5736</th>\n",
       "      <td>2132</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>2132_right.jpg</td>\n",
       "      <td>normal fundus</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5737</th>\n",
       "      <td>4487</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>4487_right.jpg</td>\n",
       "      <td>mild nonproliferative retinopathy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5738 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Patient Age  Patient Sex           Image  \\\n",
       "0      970           56            0   970_right.jpg   \n",
       "1      127           52            1    127_left.jpg   \n",
       "2      850           68            1   850_right.jpg   \n",
       "3       37           41            1    37_right.jpg   \n",
       "4     4421           59            1  4421_right.jpg   \n",
       "...    ...          ...          ...             ...   \n",
       "5733   199           50            0    199_left.jpg   \n",
       "5734   516           42            1   516_right.jpg   \n",
       "5735  4603           47            0   4603_left.jpg   \n",
       "5736  2132           59            0  2132_right.jpg   \n",
       "5737  4487           55            0  4487_right.jpg   \n",
       "\n",
       "                                               Keywords  eye  N  D  G  C  A  \\\n",
       "0                                              cataract    0  0  0  0  1  0   \n",
       "1     proliferative diabetic retinopathy，hypertensiv...    1  0  1  0  0  0   \n",
       "2     macular epiretinal membrane，moderate non proli...    1  0  1  0  0  0   \n",
       "3                                         normal fundus    1  1  0  0  0  0   \n",
       "4                moderate non proliferative retinopathy    1  0  1  0  0  0   \n",
       "...                                                 ...  ... .. .. .. .. ..   \n",
       "5733                      branch retinal vein occlusion    0  0  0  0  0  0   \n",
       "5734             moderate non proliferative retinopathy    1  0  1  0  0  0   \n",
       "5735                severe nonproliferative retinopathy    0  0  1  0  0  0   \n",
       "5736                                      normal fundus    0  1  0  0  0  0   \n",
       "5737                  mild nonproliferative retinopathy    0  0  1  0  0  0   \n",
       "\n",
       "      H  M  O  NOT DECISIVE  \n",
       "0     0  0  0             0  \n",
       "1     0  0  0             0  \n",
       "2     0  0  0             0  \n",
       "3     0  0  0             0  \n",
       "4     0  0  0             0  \n",
       "...  .. .. ..           ...  \n",
       "5733  0  0  1             0  \n",
       "5734  0  0  0             0  \n",
       "5735  0  0  0             0  \n",
       "5736  0  0  0             0  \n",
       "5737  0  0  0             0  \n",
       "\n",
       "[5738 rows x 15 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(train_val_df['Keywords'].apply(lambda x: len(x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4877, 861)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, val_df = train_test_split(train_val_df, test_size = 0.15, random_state= 123456)\n",
    "len(train_df), len(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "rescale_transform = torchvision.transforms.Compose([\n",
    "    #torchvision.transforms.CenterCrop(IMG_SIZE),\n",
    "    torchvision.transforms.Resize(IMG_SIZE, antialias = False, interpolation = torchvision.transforms.InterpolationMode.NEAREST),\n",
    "    torchvision.transforms.Normalize(\n",
    "        timm.data.constants.IMAGENET_DEFAULT_MEAN,\n",
    "        timm.data.constants.IMAGENET_DEFAULT_STD\n",
    "    )\n",
    "])\n",
    "\n",
    "augmentation = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.PILToTensor(),\n",
    "    torchvision.transforms.Resize(IMG_SIZE, antialias = False, interpolation = torchvision.transforms.InterpolationMode.NEAREST),\n",
    "#     torchvision.transforms.RandomHorizontalFlip(p = 0.5),\n",
    "#     torchvision.transforms.RandomVerticalFlip(p= 0.5),\n",
    "    #torchvision.transforms.RandomRotation(90)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56,  0],\n",
       "       [52,  1],\n",
       "       [68,  1],\n",
       "       ...,\n",
       "       [47,  0],\n",
       "       [59,  0],\n",
       "       [55,  0]], dtype=int64)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.c_[train_val_df['Patient Age'].to_numpy(), train_val_df['Patient Sex'].to_numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODIRDataset(Dataset) :\n",
    "    def __init__(self, df, IMG_FOLDER, extractor = rescale_transform, augmentation = None) :\n",
    "        '''\n",
    "        id : list of samples ids as string\n",
    "        '''\n",
    "        #self.text = [tokenizer(text = x, padding = 'max_length', max_length = 40, truncation = True, return_tensors = 'pt') for x in df['Keywords']]\n",
    "        self.images = [Image.open(IMG_PATH + x).convert(\"RGB\") for x in df['Image']]\n",
    "        self.hist_images = [Image.open(HIST_IMG_PATH + x).convert(\"RGB\") for x in df['Image']]\n",
    "        processor = AutoImageProcessor.from_pretrained(\"microsoft/swinv2-tiny-patch4-window8-256\")\n",
    "        self.images = [processor(x, return_tensors=\"pt\") for x in self.images]\n",
    "        self.hist_images = [processor(x, return_tensors=\"pt\") for x in self.hist_images]\n",
    "        sex = df['Patient Age'].to_numpy()\n",
    "        age = (df['Patient Age']/df['Patient Age'].max()).to_numpy()\n",
    "        self.feats = torch.tensor(np.c_[sex, age], requires_grad= True)\n",
    "        self.labels = torch.tensor(df[['N', 'D', 'G', 'C', 'A', 'H', 'M', 'O']].to_numpy()).float()\n",
    "        self.img_dir = [IMG_PATH + x for x in df['Image']]\n",
    "\n",
    "        self.augmentation = augmentation\n",
    "\n",
    "#         self.images = [extractor(torchvision.io.read_image(x)/255.0) for x in self.img_dir]\n",
    "        #self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        batch_imgs = self.images[idx]\n",
    "        batch_hist_imgs = self.hist_images[idx]\n",
    "#         if(self.augmentation is not None):\n",
    "#             batch_imgs = self.augmentation(batch_imgs)\n",
    "        return batch_imgs, batch_hist_imgs, self.feats[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = ODIRDataset(train_df, IMG_PATH, augmentation = augmentation)\n",
    "# val_dataset   = ODIRDataset(val_df, IMG_PATH)\n",
    "# test_dataset  = ODIRDataset(test_df, IMG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"datasets_en.trch\", 'wb') as f:\n",
    "#     torch.save([train_dataset, val_dataset, test_dataset], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets_en.trch\", 'rb') as f:\n",
    "    train_dataset, val_dataset, test_dataset = torch.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size= BATCH_SIZE, shuffle = True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size = BATCH_SIZE)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size= BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinTv2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.base = Swinv2Model.from_pretrained(\"microsoft/swinv2-tiny-patch4-window8-256\")\n",
    "        self.base.pooler = nn.AdaptiveAvgPool1d(output_size=1)\n",
    "        self.fc = nn.Linear(768+2, 1000)\n",
    "        self.img_head = nn.Linear(1000, 8)\n",
    "\n",
    "    \n",
    "    def forward(self, pixel_values, add_info):\n",
    "        pixel_values = pixel_values['pixel_values']\n",
    "        pixel_values = pixel_values.squeeze(1)\n",
    "        out = self.base(pixel_values)['pooler_output']\n",
    "        out = torch.hstack([out, add_info])\n",
    "        out = F.relu(self.fc(out))\n",
    "        out = self.img_head(out)\n",
    "\n",
    "        out = F.sigmoid(out)\n",
    "        return out#, img_outs, txt_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path, device=\"cpu\"):\n",
    "    model = SwinTv2().to(device)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class en_SwinTv2():    \n",
    "    def __init__(self, normal_path, grey_path) :\n",
    "        self.normal_SwinTv2 = load_model(normal_path,device=\"cuda\")\n",
    "        self.grey_SwinTv2 = load_model(grey_path,device=\"cuda\")\n",
    "        \n",
    "    def test_sample(self, sample, sample_hist, train_metadata):\n",
    "        output_normal = self.normal_SwinTv2(sample, train_metadata)\n",
    "        output_grey = self.grey_SwinTv2(sample_hist, train_metadata)\n",
    "        outputs = torch.add(output_normal, output_grey)\n",
    "        outputs = torch.div(outputs, 2)\n",
    "        return outputs\n",
    "\n",
    "    def test(self, test_loader):\n",
    "        self.normal_SwinTv2.eval()\n",
    "        self.grey_SwinTv2.eval()\n",
    "        with torch.no_grad():\n",
    "            torch.cuda.empty_cache()\n",
    "            test_loss = 0\n",
    "            test_acc  = 0\n",
    "\n",
    "            AVERAGING = 'micro'\n",
    "            PREC = torchmetrics.classification.MultilabelPrecision(8, average = AVERAGING).to(device)#, validate_args = False)\n",
    "            ACC = torchmetrics.classification.MultilabelAccuracy(8, average = AVERAGING).to(device)#, validate_args = False)\n",
    "            REC = torchmetrics.classification.MultilabelRecall(8, average = AVERAGING).to(device)#, validate_args = False)\n",
    "            F1_SCORE = torchmetrics.classification.MultilabelF1Score(8, average = AVERAGING).to(device)#, validate_args = False)\n",
    "            F_BETA_SCORE = torchmetrics.classification.MultilabelFBetaScore(beta = 0.8, num_classes = 8, num_labels = 8, average = AVERAGING).to(device)#, validate_args = False)\n",
    "            KAPPA = torchmetrics.classification.MulticlassCohenKappa(8).to(device)#, validate_args = False)\n",
    "            AUC = torchmetrics.classification.MultilabelAUROC(8, average = AVERAGING).to(device)#, validate_args = False)\n",
    "\n",
    "            for train_image, train_hist_image, train_metadata, train_label in tqdm(test_dataloader): \n",
    "                with torch.no_grad():\n",
    "                    optimizer.zero_grad()\n",
    "                    train_label = train_label.to(device)\n",
    "                    train_image = train_image.to(device)\n",
    "                    train_hist_image = train_hist_image.to(device)\n",
    "                    train_metadata = train_metadata.to(device).float()\n",
    "\n",
    "\n",
    "                    predictions = self.test_sample(train_image, train_hist_image, train_metadata)\n",
    "\n",
    "\n",
    "                    train_label = train_label.long()\n",
    "                    PREC(predictions, train_label)\n",
    "                    ACC(predictions, train_label)\n",
    "                    REC(predictions, train_label)\n",
    "                    F1_SCORE(predictions, train_label)\n",
    "                    F_BETA_SCORE(predictions, train_label)\n",
    "                    KAPPA(predictions, train_label)\n",
    "                    AUC(predictions, train_label)\n",
    "\n",
    "\n",
    "            add_prec = PREC.compute()\n",
    "            add_acc = ACC.compute()\n",
    "            add_rec = REC.compute()\n",
    "            add_f1 = F1_SCORE.compute()\n",
    "            add_fbeta = F_BETA_SCORE.compute()\n",
    "            add_kappa = KAPPA.compute()\n",
    "            add_auc = AUC.compute()\n",
    "\n",
    "            avg_test_loss = test_loss/len(test_df)*BATCH_SIZE\n",
    "            avg_test_acc  = test_acc /len(test_df)\n",
    "\n",
    "            print(\"Acc: {:3f}\\nPrec: {:3f}\\nRecall: {:.3f}\\nF1-score: {:.3f}\\nF-Beta-score: {:.3f}\\nKappa: {:.3f}\\nAUC: {:.3f}\".format(add_acc, add_prec,add_rec, add_f1, add_fbeta, add_kappa, add_auc))\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #criterion = nn.BCELoss(torch.tensor([0.5, 1, 5, 5, 5, 6, 5, 1]).float().to(device))\n",
    "\n",
    "# test_loss = 0\n",
    "# test_acc  = 0\n",
    "\n",
    "# AVERAGING = 'micro'\n",
    "# PREC = torchmetrics.classification.MultilabelPrecision(8, average = AVERAGING).to(device)#, validate_args = False)\n",
    "# ACC = torchmetrics.classification.MultilabelAccuracy(8, average = AVERAGING).to(device)#, validate_args = False)\n",
    "# REC = torchmetrics.classification.MultilabelRecall(8, average = AVERAGING).to(device)#, validate_args = False)\n",
    "# F1_SCORE = torchmetrics.classification.MultilabelF1Score(8, average = AVERAGING).to(device)#, validate_args = False)\n",
    "# F_BETA_SCORE = torchmetrics.classification.MultilabelFBetaScore(beta = 0.8, num_classes = 8, num_labels = 8, average = AVERAGING).to(device)#, validate_args = False)\n",
    "# KAPPA = torchmetrics.classification.MulticlassCohenKappa(8).to(device)#, validate_args = False)\n",
    "# AUC = torchmetrics.classification.MultilabelAUROC(8, average = AVERAGING).to(device)#, validate_args = False)\n",
    "\n",
    "# for train_image, train_metadata, train_label in tqdm(test_dataloader): \n",
    "#     with torch.no_grad():\n",
    "#         optimizer.zero_grad()\n",
    "#         train_label = train_label.to(device)\n",
    "#         train_image = train_image.to(device)\n",
    "#         train_metadata = train_metadata.to(device)\n",
    "      \n",
    "\n",
    "#         predictions = model(train_image, train_metadata)\n",
    "\n",
    "\n",
    "#         train_label = train_label.long()\n",
    "#         PREC(predictions, train_label)\n",
    "#         ACC(predictions, train_label)\n",
    "#         REC(predictions, train_label)\n",
    "#         F1_SCORE(predictions, train_label)\n",
    "#         F_BETA_SCORE(predictions, train_label)\n",
    "#         KAPPA(predictions, train_label)\n",
    "#         AUC(predictions, train_label)\n",
    "\n",
    "\n",
    "# add_prec = PREC.compute()\n",
    "# add_acc = ACC.compute()\n",
    "# add_rec = REC.compute()\n",
    "# add_f1 = F1_SCORE.compute()\n",
    "# add_fbeta = F_BETA_SCORE.compute()\n",
    "# add_kappa = KAPPA.compute()\n",
    "# add_auc = AUC.compute()\n",
    "\n",
    "# avg_test_loss = test_loss/len(test_df)*BATCH_SIZE\n",
    "# avg_test_acc  = test_acc /len(test_df)\n",
    "\n",
    "# print(\"Acc: {:3f}\\nPrec: {:3f}\\nRecall: {:.3f}\\nF1-score: {:.3f}\\nF-Beta-score: {:.3f}\\nKappa: {:.3f}\\nAUC: {:.3f}\".format(add_acc, add_prec,add_rec, add_f1, add_fbeta, add_kappa, add_auc))\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab06b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a98638b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/swinv2-tiny-patch4-window8-256 were not used when initializing Swinv2Model: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing Swinv2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Swinv2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at microsoft/swinv2-tiny-patch4-window8-256 were not used when initializing Swinv2Model: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing Swinv2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Swinv2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "SwinTv2_en = en_SwinTv2(\"finetuned_swint_rgb.pt\", \"finetuned_swint_hist.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                                                 Param #\n",
       "===============================================================================================\n",
       "SwinTv2                                                                --\n",
       "├─Swinv2Model: 1-1                                                     --\n",
       "│    └─Swinv2Embeddings: 2-1                                           --\n",
       "│    │    └─Swinv2PatchEmbeddings: 3-1                                 4,704\n",
       "│    │    └─LayerNorm: 3-2                                             192\n",
       "│    │    └─Dropout: 3-3                                               --\n",
       "│    └─Swinv2Encoder: 2-2                                              --\n",
       "│    │    └─ModuleList: 3-4                                            27,571,722\n",
       "│    └─LayerNorm: 2-3                                                  1,536\n",
       "│    └─AdaptiveAvgPool1d: 2-4                                          --\n",
       "├─Linear: 1-2                                                          771,000\n",
       "├─Linear: 1-3                                                          8,008\n",
       "===============================================================================================\n",
       "Total params: 28,357,162\n",
       "Trainable params: 28,357,162\n",
       "Non-trainable params: 0\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "\n",
    "torchinfo.torchinfo.summary(SwinTv2_en.grey_SwinTv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6451a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:10<00:00,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.917124\n",
      "Prec: 0.725367\n",
      "Recall: 0.542\n",
      "F1-score: 0.621\n",
      "F-Beta-score: 0.641\n",
      "Kappa: 0.000\n",
      "AUC: 0.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "SwinTv2_en.test(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "aae2c75324e7fdf5ebd22146e2daffaa477f8ea149f0e685be4c317c2939a685"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
